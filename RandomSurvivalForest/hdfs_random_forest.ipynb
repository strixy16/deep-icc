{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pysurvival\n",
    "import rpy2.robjects as robjects\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from statistics import mean, stdev\n",
    "\n",
    "from pysurvival.utils.display import correlation_matrix\n",
    "from pysurvival.models.survival_forest import RandomSurvivalForestModel\n",
    "from pysurvival.utils.metrics import concordance_index, integrated_brier_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from lifelines import CoxPHFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need to run this once\n",
    "utils = rpackages.importr('utils')\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "utils.install_packages(\"survAUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cox_feature_select(X, t, e):\n",
    "    num_samples = X.shape[0]\n",
    "    num_events = sum(e)\n",
    "\n",
    "    data_table = X\n",
    "    data_table['Time'] = t\n",
    "    data_table['Event'] = e\n",
    "\n",
    "    max_num_features = math.ceil(num_events/10)\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(data_table, duration_col='Time', event_col='Event')\n",
    "\n",
    "    hr = abs(cph.params_)\n",
    "    \n",
    "    filtered_hr = hr.nlargest(n=max_num_features, keep='first')\n",
    "    index_names = filtered_hr.index\n",
    "\n",
    "    col_names = []\n",
    "    for x in range(1, len(index_names)):\n",
    "        col_names.append(index_names[x])\n",
    "\n",
    "    filtered_X = X.filter(items=col_names, axis=1)\n",
    "    print(\"Cox filter remaining variables: \\n\", filtered_X.columns)\n",
    "\n",
    "    return filtered_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif(X, thresh=10):\n",
    "    variables = list(range(X.shape[1]))\n",
    "    dropped=True\n",
    "\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        vif = [variance_inflation_factor(X.iloc[:, variables].values, ix) \\\n",
    "               for ix in range(X.iloc[:, variables].shape[1])]\n",
    "    \n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            # print(\"Dropping \\'\" + X.iloc[:, variables].columns[maxloc] + \"\\' at index: \"+ str(maxloc))\n",
    "            del variables[maxloc]\n",
    "            dropped = True\n",
    "    \n",
    "    print('VIF remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X.iloc[:, variables]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gh_c_index(risk_pred):\n",
    "    \"\"\"\n",
    "    Calculate Gonen and Hiller's c-index using function from R (using rpy2) \n",
    "\n",
    "    Args:\n",
    "        risk_pred: np.ndarray or torch.Tensor, risk score predictions from model\n",
    "\n",
    "    Source: Gonen, M. and G. Heller (2005). \n",
    "    Concordance probability and discriminatory power in proportional hazards regression.\n",
    "    Biometrika 92, 965â€“970.\n",
    "    \"\"\"\n",
    "\n",
    "    # check for NaNs\n",
    "    if not isinstance(risk_pred, np.ndarray):\n",
    "        risk_pred = risk_pred.detach().cpu().numpy()\n",
    "    for a in risk_pred:\n",
    "        if np.isnan(a).any():\n",
    "            raise ValueError(\"NaNs detected in inputs, please correct or drop.\")\n",
    "\n",
    "    # Use Gonen and Hiller's c-index via the survAUC library in R\n",
    "    survAUC = rpackages.importr('survAUC')\n",
    "\n",
    "    # Get data into right format\n",
    "    R_risk_pred = robjects.vectors.FloatVector(risk_pred)\n",
    "\n",
    "    # this doesn't work yet, need to get the list to numeric type\n",
    "    # in R, this is accomplished with as.numeric and unlist()\n",
    "    R_cind = survAUC.GHCI(R_risk_pred)\n",
    "\n",
    "    # Convert back to Python list with single value\n",
    "    cind = list(R_cind)\n",
    "\n",
    "    # Return the only value in the cind list\n",
    "    return cind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_survival_model(X, t, e, num_trees, max_depth, min_node_size, seed=16):\n",
    "    \"\"\"\n",
    "    Function to create and run Random Survival Forest with given attributes on data.\n",
    "\n",
    "    Args:\n",
    "        X: array -- input features, rows as samples\n",
    "        t: array -- time labels for X, when event of interest or censoring occurred\n",
    "        e: array -- event labels for X, if event occurred (1=event, 0=censoring)\n",
    "        num_trees: int -- number of trees that will be built in forest model, used in initialization of model\n",
    "        max_depth: int -- maximum number of levels allowed in tree, used in model fit\n",
    "        min_node_size: int -- minimum number of samples required to be at leaf node, used in model fit\n",
    "        seed: int -- random seed used by random number generator in model fit\n",
    "\n",
    "    Returns: \n",
    "        rsf: pysurvival.model.RandomSurvivalForestModel -- model fit to input data\n",
    "    \"\"\"\n",
    "\n",
    "    # Create instance of the model\n",
    "    rsf = RandomSurvivalForestModel(num_trees=num_trees)\n",
    "\n",
    "    # Fit model to data\n",
    "    # Arguments not used from function input are defaults except importance_mode\n",
    "    # TODO: need to find out what importance mode is \n",
    "    rsf.fit(X, t, e, max_features='all', max_depth=max_depth, min_node_size=min_node_size,\n",
    "            num_threads=-1, sample_size_pct=0.63,\n",
    "            seed=seed, save_memory=False)\n",
    "\n",
    "\n",
    "    return rsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forest(rsf, XT, tT, eT):\n",
    "    \n",
    "    risk = rsf.predict_risk(XT)\n",
    "    h_c_ind = concordance_index(rsf, XT, tT, eT)\n",
    "    gh_c_ind = gh_c_index(risk)\n",
    "    ibs = integrated_brier_score(rsf, XT, tT, eT)\n",
    "\n",
    "    return h_c_ind, gh_c_ind, ibs, risk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_train_survival_model(X, t, e, num_trees, max_depth, min_node_size, k=5, seed=16):\n",
    "    CI = []\n",
    "    CPE = []\n",
    "    IBS = []\n",
    "\n",
    "    best_fold = 0\n",
    "    best_CI = 0\n",
    "    # best_GHCI = 0\n",
    "    # best_IBS = 0 \n",
    "    best_fold_rsf = None\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=k, random_state=seed, shuffle=True)\n",
    "\n",
    "    history = {'train_CI': [], 'train_CPE': [], 'train_IBS': [], \n",
    "               'valid_CI': [], 'valid_CPE': [], 'valid_IBS': [],}\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X, e)):\n",
    "        # Output current fold number\n",
    "        # print('Fold {}'.format(fold + 1))\n",
    "\n",
    "        X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n",
    "        t_train, t_val = t.loc[train_idx], t.loc[val_idx]\n",
    "        e_train, e_val = e.loc[train_idx], e.loc[val_idx]\n",
    "\n",
    "        fold_rsf = train_survival_model(X_train, t_train, e_train, num_trees, max_depth, min_node_size, seed)\n",
    "\n",
    "        train_h_c_ind, train_cpe, train_ibs = evaluate_forest(fold_rsf, X_train, t_train, e_train)\n",
    "        val_h_c_ind, val_cpe, val_ibs, _ = evaluate_forest(fold_rsf, X_val, t_val, e_val)\n",
    "\n",
    "        history['train_CI'].append(train_h_c_ind)\n",
    "        history['train_CPE'].append(train_cpe)\n",
    "        history['train_IBS'].append(train_ibs)\n",
    "        history['valid_CI'].append(val_h_c_ind)\n",
    "        history['valid_CPE'].append(val_cpe)\n",
    "        history['valid_IBS'].append(val_ibs)\n",
    "\n",
    "        if best_CI < val_h_c_ind:\n",
    "            best_CI = val_h_c_ind\n",
    "            best_fold = fold\n",
    "            best_fold_rsf = fold_rsf\n",
    "\n",
    "    \n",
    "    train_CI_avg = mean(history['train_CI'])\n",
    "    train_CI_std = stdev(history['train_CI'])\n",
    "    train_GHCI_avg = mean(history['train_CPE'])\n",
    "    train_GHCI_std = stdev(history['train_CPE'])\n",
    "    train_IBS_avg = mean(history['train_IBS'])\n",
    "    train_IBS_std = stdev(history['train_IBS'])\n",
    "\n",
    "    valid_CI_avg = mean(history['valid_CI'])\n",
    "    valid_CI_std = stdev(history['valid_CI'])\n",
    "    valid_GHCI_avg = mean(history['valid_CPE'])\n",
    "    valid_GHCI_std = stdev(history['valid_CPE'])\n",
    "    valid_IBS_avg = mean(history['valid_IBS'])\n",
    "    valid_IBS_std = stdev(history['valid_IBS'])\n",
    "\n",
    "\n",
    "\n",
    "    avg_train_fold_results = {'CI_avg': train_CI_avg, 'CI_std': train_CI_std, \n",
    "                              'GHCI_avg': train_GHCI_avg, 'GHCI_std': train_GHCI_std,\n",
    "                              'IBS_avg': train_IBS_avg, 'IBS_std': train_IBS_std}\n",
    "\n",
    "    avg_valid_fold_results = {'CI_avg': valid_CI_avg, 'CI_std': valid_CI_std, \n",
    "                              'GHCI_avg': valid_GHCI_avg, 'GHCI_std': valid_GHCI_std,\n",
    "                              'IBS_avg': valid_IBS_avg, 'IBS_std': valid_IBS_std}\n",
    "\n",
    "    best_fold_results = {'train_CI': history['train_CI'][best_fold],\n",
    "                         'train_CPE': history['train_CPE'][best_fold],\n",
    "                         'train_IBS': history['train_IBS'][best_fold],\n",
    "                         'valid_CI': history['valid_CI'][best_fold],\n",
    "                         'valid_CPE': history['valid_CPE'][best_fold],\n",
    "                         'valid_IBS': history['valid_IBS'][best_fold]}\n",
    "\n",
    "    return avg_train_fold_results, avg_valid_fold_results, best_fold_results, best_fold_rsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_survival_model(X, t, e):\n",
    "    \"\"\"\n",
    "    Function to run a gridsearch on various Random Survival Forest hyperparameters\n",
    "\n",
    "    Args:\n",
    "        X: array -- input features, rows as samples\n",
    "        t: array -- time labels for X, when event of interest or censoring occurred\n",
    "        e: array -- event labels for X, if event occurred (1=event, 0=censoring)\n",
    "    \"\"\"\n",
    "    num_tree=(15, 20, 25, 30, 35)\n",
    "    max_depth=(4, 6, 8, 12, 15)\n",
    "    min_node=(3, 5, 8, 10)\n",
    "    num_tree_best = 0\n",
    "    max_depth_best = 0\n",
    "    min_node_best = 0\n",
    "    # c_index_best = 0\n",
    "    # ghci_best = 0\n",
    "    avg_train_results = None\n",
    "    avg_valid_results = None\n",
    "    best_overall_results = None\n",
    "    best_rsf = None\n",
    "\n",
    "\n",
    "    for a in num_tree:\n",
    "        for b in max_depth:\n",
    "            for c in min_node:\n",
    "                avg_train_fold_results, avg_valid_fold_results, best_fold_results, best_fold_rsf = \\\n",
    "                    kfold_train_survival_model(X, t, e, num_trees=a, max_depth=b, min_node_size=c, k=5, seed=16)\n",
    "                # print(a, b, c, CI_avg)\n",
    "                best_val_ci = best_fold_results['valid_CI']\n",
    "                if best_val_ci > c_index_best:\n",
    "                    c_index_best = best_val_ci\n",
    "                    avg_train_results = avg_train_fold_results\n",
    "                    avg_valid_results = avg_train_fold_results\n",
    "                    best_overall_results = best_fold_results\n",
    "                    num_tree_best = a\n",
    "                    max_depth_best = b\n",
    "                    min_node_best = c\n",
    "                    best_rsf = best_fold_rsf\n",
    "\n",
    "    return num_tree_best, max_depth_best, min_node_best, avg_train_results, avg_valid_results, best_overall_results, best_rsf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/Data/FeatureSelection/HCC_MCRC_ICC_HDFS_90_10/\"\n",
    "\n",
    "train_liver_data = pd.read_excel(os.path.join(data_folder, \"train_liver_feats_and_labels.xlsx\"))\n",
    "test_liver_data = pd.read_excel(os.path.join(data_folder, \"test_liver_feats_and_labels.xlsx\"))\n",
    "\n",
    "features_to_drop=[]\n",
    "# features_to_drop = ['LeastAxisLength', '90Percentile', 'Contrast', 'MeshVolume', 'Complexity', 'MinorAxisLength', \\\n",
    "#                     '10Percentile', 'Uniformity', 'Mean', 'Energy', 'InterquartileRange', 'TotalEnergy', 'Busyness', \\\n",
    "#                     'RootMeanSquared', 'Maximum3DDiameter']\n",
    "\n",
    "X_liver = train_liver_data.drop(labels=[\"ScoutID\", \"HDFS_Time\", \"HDFS_Code\", \"Cancer_Type\"], axis=1)\n",
    "X_liver = X_liver.drop(labels=features_to_drop, axis=1)\n",
    "t_liver = train_liver_data[\"HDFS_Time\"]\n",
    "e_liver = train_liver_data[\"HDFS_Code\"]\n",
    "\n",
    "XT_liver = test_liver_data.drop(labels=[\"ScoutID\", \"HDFS_Time\", \"HDFS_Code\", \"Cancer_Type\"], axis=1)\n",
    "XT_liver = XT_liver.drop(labels=features_to_drop, axis=1)\n",
    "tT_liver = test_liver_data[\"HDFS_Time\"]\n",
    "eT_liver = test_liver_data[\"HDFS_Code\"]\n",
    "\n",
    "\n",
    "# CI_avg, GHCI_avg, IBS_avg, best_CI, best_GHCI, best_IBS, best_fold_rsf = kfold_train_survival_model(\\\n",
    "#     X_liver, t_liver, e_liver, num_trees=5, max_depth=5, min_node_size=5, k=5, seed=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/statsmodels/stats/outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF remaining variables:\n",
      "Index(['Kurtosis', 'Skewness', 'Variance', 'Busyness', 'Coarseness',\n",
      "       'Complexity', 'Contrast', 'Strength', 'Flatness', 'SurfaceArea'],\n",
      "      dtype='object')\n",
      "Cox filter remaining variables: \n",
      " Index(['Contrast', 'Flatness', 'Strength', 'Skewness', 'Kurtosis', 'Busyness',\n",
      "       'Complexity', 'Variance', 'SurfaceArea'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lifelines/utils/__init__.py:1103: ConvergenceWarning: Column(s) ['Coarseness', 'Contrast'] have very low variance. This may harm convergence. 1) Are you using formula's? Did you mean to add '-1' to the end. 2) Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "liver_vselected_features = calculate_vif(X_liver, 10)\n",
    "X_liver = liver_vselected_features\n",
    "\n",
    "X_liver = cox_feature_select(X_liver, t_liver, e_liver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gh_c_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3360400/868934725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mliv_c_index_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliv_ghci_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliv_num_tree_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliv_max_depth_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliv_min_node_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliv_best_fold_rsf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridsearch_survival_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_liver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_liver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_liver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best c-index:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mliv_c_index_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(ghci_best)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best num_tree val:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mliv_num_tree_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3360400/3116948510.py\u001b[0m in \u001b[0;36mgridsearch_survival_model\u001b[0;34m(X, t, e)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmin_node\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mCI_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGHCI_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIBS_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_CI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_GHCI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_IBS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_fold_rsf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                     \u001b[0mkfold_train_survival_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_trees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_node_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0;31m# print(a, b, c, CI_avg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mCI_avg\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mc_index_best\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3360400/3049672398.py\u001b[0m in \u001b[0;36mkfold_train_survival_model\u001b[0;34m(X, t, e, num_trees, max_depth, min_node_size, k, seed)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfold_rsf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_survival_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_trees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_node_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mfold_h_c_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_gh_c_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_ibs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_rsf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mCI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_h_c_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3360400/733346510.py\u001b[0m in \u001b[0;36mevaluate_forest\u001b[0;34m(rsf, XT, tT, eT)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrisk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrsf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_risk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mh_c_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcordance_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrsf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgh_c_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgh_c_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrisk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mibs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintegrated_brier_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrsf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gh_c_index' is not defined"
     ]
    }
   ],
   "source": [
    "liv_c_index_best, liv_ghci_best, liv_num_tree_best, liv_max_depth_best, liv_min_node_best, liv_best_fold_rsf = gridsearch_survival_model(X_liver, t_liver, e_liver)\n",
    "\n",
    "print(\"Best c-index:\",liv_c_index_best)\n",
    "# print(ghci_best)\n",
    "print(\"Best num_tree val:\",liv_num_tree_best)\n",
    "print(\"Best max_depth val:\", liv_max_depth_best)\n",
    "print(\"Best min_node val:\",liv_min_node_best)\n",
    "\n",
    "# liver_rsf = train_survival_model(X_liver, t_liver, e_liver, num_trees=liv_num_tree_best, max_depth=liv_max_depth_best, min_node_size=liv_min_node_best, seed=16)\n",
    "\n",
    "# train_liver_cind, train_liver_ghci, train_liver_ibs, train_liver_riskpred = evaluate_forest(liv__rsf, X_liver, t_liver, e_liver)\n",
    "\n",
    "liver_h_c_ind, liver_gh_c_ind, liver_ibs, liver_riskpreds = evaluate_forest(liv_best_fold_rsf, XT_liver, tT_liver, eT_liver)\n",
    "\n",
    "# print(\"Training: \")\n",
    "# print(\"Harrel's C-index: \", train_liver_cind)\n",
    "# print(\"GH C-index: \", train_liver_ghci)\n",
    "# print(\"IBS: \", train_liver_ibs)\n",
    "\n",
    "print()\n",
    "print(\"Testing: \")\n",
    "print(\"Harrel's C-index: \", liver_h_c_ind)\n",
    "print(\"GH C-index: \", liver_gh_c_ind)\n",
    "print(\"IBS: \", liver_ibs)\n",
    "\n",
    "liv_var_imps = liver_rsf.variable_importance_table\n",
    "liv_var_imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_liver_predictions = test_liver_data.loc[:, ['ScoutID', \"HDFS_Time\", \"HDFS_Code\", \"Cancer_Type\"]]\n",
    "test_liver_predictions['Prediction'] = liver_riskpreds\n",
    "test_liver_predictions.to_excel(os.path.join(data_folder, \"RSF_test_liver_predictions_90_10.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading and Setup\n",
    "data_folder = \"/Data/FeatureSelection/HCC_MCRC_ICC_HDFS_90_10/\"\n",
    "\n",
    "train_tumor_data = pd.read_excel(os.path.join(data_folder, \"train_tumor_feats_and_labels.xlsx\"))\n",
    "test_tumor_data = pd.read_excel(os.path.join(data_folder, \"test_tumor_feats_and_labels.xlsx\"))\n",
    "\n",
    "features_to_drop = []\n",
    "# features_to_drop = ['SurfaceVolumeRatio', 'Maximum2DDiameterSlice', 'MajorAxisLength', 'Busyness', 'VoxelVolume',\\\n",
    "                    # '90Percentile', 'Median', 'Energy', 'RootMeanSquared']\n",
    "\n",
    "X_tumor = train_tumor_data.drop(labels=[\"ScoutID\", \"HDFS_Time\", \"HDFS_Code\", \"Cancer_Type\"], axis=1)\n",
    "X_tumor = X_tumor.drop(labels=features_to_drop, axis=1)\n",
    "t_tumor = train_tumor_data[\"HDFS_Time\"]\n",
    "e_tumor = train_tumor_data[\"HDFS_Code\"]\n",
    "\n",
    "XT_tumor = test_tumor_data.drop(labels=[\"ScoutID\", \"HDFS_Time\", \"HDFS_Code\", \"Cancer_Type\"], axis=1)\n",
    "XT_tumor = XT_tumor.drop(labels=features_to_drop, axis=1)\n",
    "tT_tumor = test_tumor_data[\"HDFS_Time\"]\n",
    "eT_tumor = test_tumor_data[\"HDFS_Code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/statsmodels/stats/outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF remaining variables:\n",
      "Index(['10Percentile', 'Kurtosis', 'Minimum', 'TotalEnergy', 'Busyness',\n",
      "       'Coarseness', 'Complexity', 'Contrast', 'Strength', 'Flatness',\n",
      "       'Maximum2DDiameterColumn', 'MeshVolume'],\n",
      "      dtype='object')\n",
      "Cox filter remaining variables: \n",
      " Index(['Contrast', 'Flatness', 'Strength', 'Maximum2DDiameterColumn',\n",
      "       '10Percentile', 'Kurtosis', 'Busyness', 'Complexity', 'Minimum',\n",
      "       'MeshVolume', 'TotalEnergy'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lifelines/utils/__init__.py:1103: ConvergenceWarning: Column(s) ['Coarseness'] have very low variance. This may harm convergence. 1) Are you using formula's? Did you mean to add '-1' to the end. 2) Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "tum_vselected_features = calculate_vif(X_tumor, 10)\n",
    "X_tumor = tum_vselected_features\n",
    "\n",
    "X_tumor = cox_feature_select(X_tumor, t_tumor, e_tumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k-fold c-index: 0.5985046356357657\n",
      "Best num_tree val: 20\n",
      "Best max_depth val: 4\n",
      "Best min_node val: 3\n",
      "Training: \n",
      "Harrel's C-index:  0.6313905604015215\n",
      "GH C-index:  0.991600139487711\n",
      "IBS:  0.19522905346033947\n",
      "Harrel's C-index:  0.6328024720032681\n",
      "GH C-index:  0.6940854107784103\n",
      "IBS:  0.282533349505983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>pct_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maximum2DDiameterColumn</td>\n",
       "      <td>4.380915</td>\n",
       "      <td>0.326096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kurtosis</td>\n",
       "      <td>2.880566</td>\n",
       "      <td>0.214416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MeshVolume</td>\n",
       "      <td>2.009008</td>\n",
       "      <td>0.149542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flatness</td>\n",
       "      <td>1.470401</td>\n",
       "      <td>0.109450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Minimum</td>\n",
       "      <td>1.334858</td>\n",
       "      <td>0.099361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TotalEnergy</td>\n",
       "      <td>0.958495</td>\n",
       "      <td>0.071346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Complexity</td>\n",
       "      <td>0.176317</td>\n",
       "      <td>0.013124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10Percentile</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>0.009487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Strength</td>\n",
       "      <td>0.096433</td>\n",
       "      <td>0.007178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Busyness</td>\n",
       "      <td>-0.078841</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Contrast</td>\n",
       "      <td>-0.273299</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  importance  pct_importance\n",
       "0   Maximum2DDiameterColumn    4.380915        0.326096\n",
       "1                  Kurtosis    2.880566        0.214416\n",
       "2                MeshVolume    2.009008        0.149542\n",
       "3                  Flatness    1.470401        0.109450\n",
       "4                   Minimum    1.334858        0.099361\n",
       "5               TotalEnergy    0.958495        0.071346\n",
       "6                Complexity    0.176317        0.013124\n",
       "7              10Percentile    0.127451        0.009487\n",
       "8                  Strength    0.096433        0.007178\n",
       "9                  Busyness   -0.078841        0.000000\n",
       "10                 Contrast   -0.273299        0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RSF Model creation and evaluation\n",
    "tum_c_index_best, tum_ghci_best, tum_num_tree_best, tum_max_depth_best, tum_min_node_best, tum_best_fold_rsf = gridsearch_survival_model(X_tumor, t_tumor, e_tumor)\n",
    "\n",
    "print(\"Best k-fold c-index:\",tum_c_index_best)\n",
    "# print(ghci_best)\n",
    "print(\"Best num_tree val:\",tum_num_tree_best)\n",
    "print(\"Best max_depth val:\", tum_max_depth_best)\n",
    "print(\"Best min_node val:\",tum_min_node_best)\n",
    "\n",
    "tumor_rsf = train_survival_model(X_tumor, t_tumor, e_tumor, num_trees=tum_num_tree_best, max_depth=tum_max_depth_best, min_node_size=tum_min_node_best, seed=16)\n",
    "train_tumor_cind, train_tumor_ghci, train_tumor_ibs, train_tumor_riskpred = evaluate_forest(tumor_rsf, X_tumor, t_tumor, e_tumor)\n",
    "tumor_h_c_ind, tumor_gh_c_ind, tumor_ibs, tumor_preds = evaluate_forest(tumor_rsf, XT_tumor, tT_tumor, eT_tumor)\n",
    "\n",
    "print(\"Training: \")\n",
    "print(\"Harrel's C-index: \", train_tumor_cind)\n",
    "print(\"GH C-index: \", train_tumor_ghci)\n",
    "print(\"IBS: \", train_tumor_ibs)\n",
    "\n",
    "print()\n",
    "print(\"Testing: \")\n",
    "print(\"Harrel's C-index: \", tumor_h_c_ind)\n",
    "print(\"GH C-index: \", tumor_gh_c_ind)\n",
    "print(\"IBS: \", tumor_ibs)\n",
    "\n",
    "tum_var_imps = tumor_rsf.variable_importance_table\n",
    "tum_var_imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tumor_predictions = test_tumor_data.loc[:, ['ScoutID', \"HDFS_Time\", \"HDFS_Code\", \"Cancer_Type\"]]\n",
    "test_tumor_predictions['Prediction'] = tumor_preds\n",
    "test_tumor_predictions.to_excel(os.path.join(data_folder, \"RSF_test_tumor_predictions_90_10.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liver and Tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/Data/FeatureSelection/HCC_MCRC_ICC_HDFS_90_10/\"\n",
    "\n",
    "train_livertumor_data = pd.read_excel(os.path.join(data_folder, \"train_liver_tumor_feats_and_labels.xlsx\"))\n",
    "test_livertumor_data = pd.read_excel(os.path.join(data_folder, \"test_liver_tumor_feats_and_labels.xlsx\"))\n",
    "\n",
    "features_to_drop = []\n",
    "# features_to_drop = ['Strength', 'MinorAxisLength', 'VoxelVolume', 'Complexity', 'Uniformity', 'Minimum', \\\n",
    "#                     'Median', 'InterquartileRange', 'Energy']\n",
    "\n",
    "X_livertumor = train_livertumor_data.drop(labels=[\"ScoutID\", \"HDFS_Time\", \"HDFS_Code\", \"Cancer_Type\"], axis=1)\n",
    "X_livertumor = X_livertumor.drop(labels=features_to_drop, axis=1)\n",
    "t_livertumor = train_livertumor_data[\"HDFS_Time\"]\n",
    "e_livertumor = train_livertumor_data[\"HDFS_Code\"]\n",
    "\n",
    "XT_livertumor = test_livertumor_data.drop(labels=[\"ScoutID\", \"HDFS_Time\", \"HDFS_Code\", \"Cancer_Type\"], axis=1)\n",
    "XT_livertumor = XT_livertumor.drop(labels=features_to_drop, axis=1)\n",
    "tT_livertumor = test_livertumor_data[\"HDFS_Time\"]\n",
    "eT_livertumor = test_livertumor_data[\"HDFS_Code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/statsmodels/stats/outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF remaining variables:\n",
      "Index(['Kurtosis', 'Skewness', 'TotalEnergy', 'Variance', 'Busyness',\n",
      "       'Complexity', 'Contrast', 'Strength', 'Flatness', 'SurfaceVolumeRatio'],\n",
      "      dtype='object')\n",
      "Cox filter remaining variables: \n",
      " Index(['SurfaceVolumeRatio', 'Flatness', 'Skewness', 'Strength', 'Kurtosis',\n",
      "       'Busyness', 'Complexity', 'Variance', 'TotalEnergy'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lifelines/utils/__init__.py:1103: ConvergenceWarning: Column(s) ['Contrast'] have very low variance. This may harm convergence. 1) Are you using formula's? Did you mean to add '-1' to the end. 2) Try dropping this redundant column before fitting if convergence fails.\n",
      "\n",
      "  warnings.warn(dedent(warning_text), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "livtum_vselected_features = calculate_vif(X_livertumor, 10)\n",
    "X_livertumor = livtum_vselected_features\n",
    "\n",
    "X_livertumor = cox_feature_select(X_livertumor, t_livertumor, e_livertumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k-fold c-index: 0.5956934851792524\n",
      "Best num_tree val: 25\n",
      "Best max_depth val: 4\n",
      "Best min_node val: 5\n",
      "Training: \n",
      "Harrel's C-index:  0.6502548268094505\n",
      "GH C-index:  0.9947531226284709\n",
      "IBS:  0.19649582923465644\n",
      "\n",
      "Testing: \n",
      "Harrel's C-index:  0.6024511048260658\n",
      "GH C-index:  0.8702756685083678\n",
      "IBS:  0.24770199890714759\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>pct_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skewness</td>\n",
       "      <td>3.941655</td>\n",
       "      <td>0.302668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variance</td>\n",
       "      <td>2.709866</td>\n",
       "      <td>0.208082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Complexity</td>\n",
       "      <td>1.856625</td>\n",
       "      <td>0.142565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Strength</td>\n",
       "      <td>1.800248</td>\n",
       "      <td>0.138236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kurtosis</td>\n",
       "      <td>1.165461</td>\n",
       "      <td>0.089492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SurfaceVolumeRatio</td>\n",
       "      <td>0.765052</td>\n",
       "      <td>0.058746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Busyness</td>\n",
       "      <td>0.539746</td>\n",
       "      <td>0.041445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Flatness</td>\n",
       "      <td>0.244388</td>\n",
       "      <td>0.018766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TotalEnergy</td>\n",
       "      <td>-0.203890</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature  importance  pct_importance\n",
       "0            Skewness    3.941655        0.302668\n",
       "1            Variance    2.709866        0.208082\n",
       "2          Complexity    1.856625        0.142565\n",
       "3            Strength    1.800248        0.138236\n",
       "4            Kurtosis    1.165461        0.089492\n",
       "5  SurfaceVolumeRatio    0.765052        0.058746\n",
       "6            Busyness    0.539746        0.041445\n",
       "7            Flatness    0.244388        0.018766\n",
       "8         TotalEnergy   -0.203890        0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livtum_c_index_best, livtum_ghci_best, livtum_num_tree_best, livtum_max_depth_best, livtum_min_node_best, livtum_best_fold_rsf = \\\n",
    "    gridsearch_survival_model(X_livertumor, t_livertumor, e_livertumor)\n",
    "\n",
    "print(\"Best k-fold c-index:\",livtum_c_index_best)\n",
    "# print(ghci_best)\n",
    "print(\"Best num_tree val:\",livtum_num_tree_best)\n",
    "print(\"Best max_depth val:\",livtum_max_depth_best)\n",
    "print(\"Best min_node val:\",livtum_min_node_best)\n",
    "\n",
    "livertumor_rsf = train_survival_model(X_livertumor, t_livertumor, e_livertumor, num_trees=livtum_num_tree_best, max_depth=livtum_max_depth_best, min_node_size=livtum_min_node_best, seed=16)\n",
    "\n",
    "train_livertumor_cind, train_livertumor_ghci, train_livertumor_ibs, train_livertumor_riskpred = evaluate_forest(livertumor_rsf, X_livertumor, t_livertumor, e_livertumor)\n",
    "\n",
    "livertumor_h_c_ind, livertumor_gh_c_ind, livertumor_ibs, livertumor_riskpreds = evaluate_forest(livertumor_rsf, XT_livertumor, tT_livertumor, eT_livertumor)\n",
    "\n",
    "print(\"Training: \")\n",
    "print(\"Harrel's C-index: \", train_livertumor_cind)\n",
    "print(\"GH C-index: \", train_livertumor_ghci)\n",
    "print(\"IBS: \", train_livertumor_ibs)\n",
    "\n",
    "print()\n",
    "print(\"Testing: \")\n",
    "print(\"Harrel's C-index: \",livertumor_h_c_ind)\n",
    "print(\"GH C-index: \",livertumor_gh_c_ind)\n",
    "print(\"IBS: \",livertumor_ibs)\n",
    "\n",
    "var_imps = livertumor_rsf.variable_importance_table\n",
    "var_imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_livertumor_predictions = test_livertumor_data.loc[:, ['ScoutID', \"HDFS_Time\", \"HDFS_Code\", \"Cancer_Type\"]]\n",
    "test_livertumor_predictions['Prediction'] = livertumor_riskpreds\n",
    "test_livertumor_predictions.to_excel(os.path.join(data_folder, \"RSF_test_liver_tumor_predictions_90_10.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_matrix(X_liver, figure_size=(30,15), text_fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "231c10b5755f24f797eb0c3c8e63bc4e4867f670e74296d317db1a43eb37d021"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('deepicc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
