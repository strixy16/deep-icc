{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from lifelines.utils import concordance_index\n",
    "import numpy as np\n",
    "import os\n",
    "from pysurvival.models.simulations import SimulationModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# from utils import *\n",
    "# from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models.py\n",
    "Code from Hassan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "    ''' The module class performs building network according to config'''\n",
    "    def __init__(self, activation):\n",
    "        ''' Initialize BasicModel class\n",
    "\n",
    "        Args:\n",
    "            activation: string, name of activation function to use\n",
    "\n",
    "        Returns:\n",
    "            torch.nn Module object, built sequential network\n",
    "        '''\n",
    "        super(BasicModel, self).__init__()\n",
    "        # parses parameters of network from configuration\n",
    "        # Set some defaults for network arguments\n",
    "        # Fraction of input units to drop in dropout layer\n",
    "        self.drop = 0.375#0.401\n",
    "        # Flag to in/exclude normalization layers\n",
    "        self.norm = True\n",
    "        # Default dimensions of fully connected layers\n",
    "        self.dims = [10, 4, 1]#10, 17, 17, 17, 1]\n",
    "        # Activation type to use\n",
    "        self.activation = activation\n",
    "        # Build network using class function (below)\n",
    "        self.model = self._build_network()\n",
    "\n",
    "    def _build_network(self):\n",
    "        ''' Performs building networks according to parameters'''\n",
    "        layers = []\n",
    "        for i in range(len(self.dims)-1):\n",
    "            if i and self.drop is not None:\n",
    "                # Add dropout layer\n",
    "                layers.append(nn.Dropout(self.drop))\n",
    "\n",
    "            # Add fully connected layer\n",
    "            layers.append(nn.Linear(self.dims[i], self.dims[i+1]))\n",
    "\n",
    "            if self.norm:\n",
    "                # Add batchnormalize layer\n",
    "                layers.append(nn.BatchNorm1d(self.dims[i+1]))\n",
    "\n",
    "            # Adds activation layer\n",
    "            # eval creates proper format of activation to get from NN\n",
    "            layers.append(eval('nn.{}()'.format(self.activation)))\n",
    "\n",
    "        # Build sequential network from list of layers created in for loop\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        ''' Forward propagation through network\n",
    "\n",
    "        Args:\n",
    "            X: data to pass through network\n",
    "\n",
    "        Returns:\n",
    "            Output of model (risk prediction)\n",
    "        '''\n",
    "        return self.model(X)\n",
    "\n",
    "\n",
    "class NegativeLogLikelihood(nn.Module):\n",
    "    '''Negative log likelihood loss function from Katzman et al. (2018) DeepSurv model (equation 4)'''\n",
    "    def __init__(self, gpu):\n",
    "        ''' Initialize NegativeLogLikelihood class\n",
    "\n",
    "        Args:\n",
    "            gpu: string, what kind of tensor to use for loss calculation\n",
    "        '''\n",
    "        super(NegativeLogLikelihood, self).__init__()\n",
    "        # self.L2_reg = 0\n",
    "        self.reg = Regularization(order=2, weight_decay=0)\n",
    "        self.device = gpu\n",
    "\n",
    "    def forward(self, risk_pred, y, e, model):\n",
    "        # Think this is getting set of patients still at risk of failure at time t???\n",
    "        mask = torch.ones(y.shape[0], y.shape[0], device=self.device)\n",
    "        mask[(y.T - y) > 0] = 0\n",
    "        log_loss = torch.exp(risk_pred) * mask\n",
    "        log_loss = torch.sum(log_loss, dim=0) / torch.sum(mask, dim=0)\n",
    "        log_loss = torch.log(log_loss).reshape(-1, 1)\n",
    "        neg_log_loss = -torch.sum((risk_pred-log_loss) * e) / torch.sum(e)\n",
    "        l2_loss = self.reg(model)\n",
    "        return neg_log_loss + l2_loss\n",
    "\n",
    "\n",
    "class NegativeLogLikelihoodStrat(nn.Module):\n",
    "    def __init__(self, gpu):\n",
    "        super(NegativeLogLikelihoodStrat, self).__init__()\n",
    "        self.device = gpu\n",
    "\n",
    "    def forward(self, risk_pred, y, e, low, high):\n",
    "        mask = torch.ones(y.shape[0], y.shape[0], device=self.device)\n",
    "        mask[(y.T - y) > 0] = 0\n",
    "        log_loss = torch.exp(risk_pred) * mask\n",
    "        log_loss = torch.sum(log_loss, dim=0) / torch.sum(mask, dim=0)\n",
    "        log_loss = torch.log(log_loss).reshape(-1, 1)\n",
    "        neg_log_loss = -torch.sum((risk_pred-log_loss) * e) / torch.sum(e)\n",
    "        strat_loss = 1 / (1 + torch.abs((high.mean() - low.mean())))\n",
    "        strat_loss = F.smooth_l1_loss(strat_loss, torch.zeros(1).squeeze().to(self.device), reduction='none').to(self.device)\n",
    "        return neg_log_loss, strat_loss\n",
    "\n",
    "\n",
    "class Regularization(object):\n",
    "    def __init__(self, order, weight_decay):\n",
    "        ''' Initialize Regularization class\n",
    "\n",
    "        Args:\n",
    "            order: int, norm order number\n",
    "            weight_decay: float, weight decay rate\n",
    "        '''\n",
    "        super(Regularization, self).__init__()\n",
    "        self.order = order\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def __call__(self, model):\n",
    "        ''' Calculates regularization(self.order) loss for model\n",
    "\n",
    "        Args:\n",
    "            model: torch.nn Module object\n",
    "\n",
    "        Returns:\n",
    "            reg_loss: torch.Tensor, regularization loss\n",
    "        '''\n",
    "        reg_loss = 0\n",
    "        for name, w in model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                reg_loss = reg_loss + torch.norm(w, p=self.order)\n",
    "        reg_loss = self.weight_decay * reg_loss\n",
    "        return reg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils.py\n",
    "Code from Hassan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurvivalDataset(Dataset):\n",
    "    def __init__(self, dataset, args):\n",
    "        '''Initialize SurvivalDataset class\n",
    "\n",
    "        Args:\n",
    "            dataset: pandas.Dataframe, Contains covariates, time of event (T), and event indicator (E) values.\n",
    "            T and E must be the final two columns\n",
    "            args: Namespace,\n",
    "        '''\n",
    "        # Get covariates out of dataframe (args.covariates is num of columns containing covariates)\n",
    "        self.X = dataset.iloc[:, 0:args.covariates].values\n",
    "        # Get time and event indicator columns out of dataframe\n",
    "        self.data = list(zip(dataset.time, dataset.event))\n",
    "        self.len = len(dataset)\n",
    "        # Normalize covariate data with class function\n",
    "        print('=> load {} samples'.format(self.len))\n",
    "        self._normalize()\n",
    "\n",
    "    def _normalize(self):\n",
    "        '''Normalize X data (covariates) (transform values to range between 0 and 1)'''\n",
    "        self.X = (self.X - self.X.min(axis=0)) / (self.X.max(axis=0) - self.X.min(axis=0))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        '''Getter for single data piece\n",
    "\n",
    "        Args:\n",
    "            item: int, index of data to retrieve\n",
    "\n",
    "        Returns:\n",
    "            X_tensor: torch.Tensor, covariate values for data item\n",
    "            y_tensor: torch.Tensor, time of event value for data item\n",
    "            e_tensor: int torch.Tensor, event indicator value for data item\n",
    "        '''\n",
    "        y, e = self.data[item]\n",
    "        X_tensor = torch.from_numpy(self.X[item])\n",
    "        e_tensor = torch.Tensor([e]).int()\n",
    "        y_tensor = torch.Tensor([y])\n",
    "        return X_tensor, y_tensor, e_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "def save_error(train_ci, val_ci, coxLoss, stratLoss, variance, epoch, slname):\n",
    "    '''Save training and validation statistics to csv file\n",
    "\n",
    "        Args:\n",
    "            train_ci: float, training concordance index for this epoch\n",
    "            val_ci: float, validation concordance index for this epoch\n",
    "            coxLoss:\n",
    "            stratLoss:\n",
    "            variance:\n",
    "            epoch: int, epoch these stats are from\n",
    "            slname: string, filename\n",
    "    '''\n",
    "    if epoch == 0:\n",
    "        # Create file for first epoch\n",
    "        f = open(slname, 'w')\n",
    "        f.write('epoch,coxLoss,stratLoss,trainCI,valCI,variance\\n')\n",
    "        f.write('{},{:.4f},{:.4f},{:.4f},{:.4f},{}\\n'.format(epoch, coxLoss, stratLoss, train_ci, val_ci, variance))\n",
    "        f.close()\n",
    "    else:\n",
    "        f = open(slname, 'a')\n",
    "        f.write('{},{:.4f},{:.4f},{:.4f},{:.4f},{}\\n'.format(epoch, coxLoss, stratLoss, train_ci, val_ci, variance))\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def c_index(risk_pred, y, e):\n",
    "    '''Calculate c-index\n",
    "\n",
    "    Args:\n",
    "        risk_pred: np.ndarray or torch.Tensor, model prediction\n",
    "        y: np.ndarray or torch.Tensor, times of event e\n",
    "        e: np.ndarray or torch.Tensor, event indicator\n",
    "\n",
    "    Returns:\n",
    "        c_index: float, concordance index\n",
    "    '''\n",
    "    # Convert risk_pred, y, and e from torch.Tensor to np.ndarray if not already\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = y.detach().cpu().numpy()\n",
    "    if not isinstance(risk_pred, np.ndarray):\n",
    "        risk_pred = risk_pred.detach().cpu().numpy()\n",
    "    if not isinstance(e, np.ndarray):\n",
    "        e = e.detach().cpu().numpy()\n",
    "    return concordance_index(y, risk_pred, e)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, lr, lr_decay_rate):\n",
    "    '''Adjust learning rate according to (epoch, lr, and lr_decay_rate)\n",
    "\n",
    "    Args:\n",
    "        optimizer: torch.optim object,\n",
    "        epoch: int, epoch number\n",
    "        lr: float, initial learning rate\n",
    "        lr_decay_rate: float, decay rate to apply to learning rate\n",
    "\n",
    "    Returns:\n",
    "        lr: float, updated learning rate\n",
    "    '''\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr / (1+epoch*lr_decay_rate)\n",
    "    return optimizer.param_groups[0]['lr']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.py\n",
    "Code from Hassan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for network\n",
    "args = Namespace(activation = 'SELU',\n",
    "                 batch_size = 4000,\n",
    "                 covariates = 10, \n",
    "                 decay_interval = 400,\n",
    "                 development = 0,\n",
    "                 dropout = 0.3,\n",
    "                 epochs = 500,\n",
    "                 lib = '',\n",
    "                 lr = 0.001,\n",
    "                 out = 1,\n",
    "                 strat = 'none',# not sure if I actually need this one\n",
    "                 weight_decay = 0.0001\n",
    "                )\n",
    "\n",
    "best_acc = 0\n",
    "# Where to allocate all the Tensors (can be 'cpu' or 'coda')\n",
    "gpu = torch.device(\"cpu\")\n",
    "\n",
    "# Setting up output path from model training\n",
    "root_output = '/Users/katyscott/Documents/ICC/Code/cox_experiments'\n",
    "\n",
    "if args.development == 1:\n",
    "    save_path = 'test'\n",
    "else:\n",
    "    save_path = '{}_{}lr_{}b_'.format(args.activation,args.lr,args.batch_size)\n",
    "    \n",
    "out_dir = os.path.join(root_output, save_path)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Build network \n",
    "model = BasicModel(args.activation).to(gpu)\n",
    "\n",
    "# Loss function\n",
    "criterion = NegativeLogLikelihood(gpu)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated Data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data-points: 4000 - Number of events: 3104.0\n",
      "Number of data-points: 500 - Number of events: 392.0\n",
      "=> load 4000 samples\n",
      "=> load 500 samples\n"
     ]
    }
   ],
   "source": [
    "# generate random survival times with exp. distribution\n",
    "sim = SimulationModel(survival_distribution='exponential',\n",
    "                      risk_type = 'Linear',\n",
    "                      censored_parameter = 6,\n",
    "                      alpha = 1,\n",
    "                      beta = 5)\n",
    "\n",
    "train_samples = sim.generate_data(num_samples = 4000,\n",
    "                                  num_features = args.covariates,\n",
    "                                  feature_weights = [1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "val_samples = sim.generate_data(num_samples = 500,\n",
    "                                num_features = args.covariates,\n",
    "                                feature_weights = [1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "train_dataset = SurvivalDataset(train_samples, args)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_dataset.__len__())\n",
    "\n",
    "val_dataset = SurvivalDataset(val_samples, args)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=val_dataset.__len__())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t Train Loss: 0.5459 \t Train CI: 0.447 \t Val CI: 0.476\n",
      "Epoch: 1 \t Train Loss: 0.5349 \t Train CI: 0.450 \t Val CI: 0.476\n",
      "Epoch: 2 \t Train Loss: 0.5306 \t Train CI: 0.454 \t Val CI: 0.477\n",
      "Epoch: 3 \t Train Loss: 0.5287 \t Train CI: 0.450 \t Val CI: 0.478\n",
      "Epoch: 4 \t Train Loss: 0.5187 \t Train CI: 0.451 \t Val CI: 0.479\n",
      "Epoch: 5 \t Train Loss: 0.5370 \t Train CI: 0.448 \t Val CI: 0.480\n",
      "Epoch: 6 \t Train Loss: 0.5373 \t Train CI: 0.448 \t Val CI: 0.481\n",
      "Epoch: 7 \t Train Loss: 0.5343 \t Train CI: 0.449 \t Val CI: 0.482\n",
      "Epoch: 8 \t Train Loss: 0.5253 \t Train CI: 0.453 \t Val CI: 0.483\n",
      "Epoch: 9 \t Train Loss: 0.5420 \t Train CI: 0.443 \t Val CI: 0.484\n",
      "Epoch: 10 \t Train Loss: 0.5158 \t Train CI: 0.455 \t Val CI: 0.485\n",
      "Epoch: 11 \t Train Loss: 0.5175 \t Train CI: 0.454 \t Val CI: 0.486\n",
      "Epoch: 12 \t Train Loss: 0.5028 \t Train CI: 0.459 \t Val CI: 0.487\n",
      "Epoch: 13 \t Train Loss: 0.5116 \t Train CI: 0.455 \t Val CI: 0.488\n",
      "Epoch: 14 \t Train Loss: 0.5084 \t Train CI: 0.455 \t Val CI: 0.489\n",
      "Epoch: 15 \t Train Loss: 0.4958 \t Train CI: 0.457 \t Val CI: 0.490\n",
      "Epoch: 16 \t Train Loss: 0.4909 \t Train CI: 0.462 \t Val CI: 0.491\n",
      "Epoch: 17 \t Train Loss: 0.4921 \t Train CI: 0.462 \t Val CI: 0.491\n",
      "Epoch: 18 \t Train Loss: 0.4959 \t Train CI: 0.459 \t Val CI: 0.492\n",
      "Epoch: 19 \t Train Loss: 0.4949 \t Train CI: 0.462 \t Val CI: 0.493\n",
      "Epoch: 20 \t Train Loss: 0.4669 \t Train CI: 0.469 \t Val CI: 0.494\n",
      "Epoch: 21 \t Train Loss: 0.4993 \t Train CI: 0.456 \t Val CI: 0.494\n",
      "Epoch: 22 \t Train Loss: 0.4796 \t Train CI: 0.464 \t Val CI: 0.495\n",
      "Epoch: 23 \t Train Loss: 0.4739 \t Train CI: 0.465 \t Val CI: 0.495\n",
      "Epoch: 24 \t Train Loss: 0.4760 \t Train CI: 0.467 \t Val CI: 0.496\n",
      "Epoch: 25 \t Train Loss: 0.4759 \t Train CI: 0.465 \t Val CI: 0.496\n",
      "Epoch: 26 \t Train Loss: 0.4658 \t Train CI: 0.475 \t Val CI: 0.497\n",
      "Epoch: 27 \t Train Loss: 0.4550 \t Train CI: 0.475 \t Val CI: 0.497\n",
      "Epoch: 28 \t Train Loss: 0.4657 \t Train CI: 0.466 \t Val CI: 0.498\n",
      "Epoch: 29 \t Train Loss: 0.4692 \t Train CI: 0.476 \t Val CI: 0.498\n",
      "Epoch: 30 \t Train Loss: 0.4623 \t Train CI: 0.474 \t Val CI: 0.499\n",
      "Epoch: 31 \t Train Loss: 0.4648 \t Train CI: 0.474 \t Val CI: 0.499\n",
      "Epoch: 32 \t Train Loss: 0.4613 \t Train CI: 0.472 \t Val CI: 0.499\n",
      "Epoch: 33 \t Train Loss: 0.4438 \t Train CI: 0.479 \t Val CI: 0.500\n",
      "Epoch: 34 \t Train Loss: 0.4346 \t Train CI: 0.481 \t Val CI: 0.500\n",
      "Epoch: 35 \t Train Loss: 0.4420 \t Train CI: 0.478 \t Val CI: 0.500\n",
      "Epoch: 36 \t Train Loss: 0.4433 \t Train CI: 0.478 \t Val CI: 0.501\n",
      "Epoch: 37 \t Train Loss: 0.4425 \t Train CI: 0.474 \t Val CI: 0.501\n",
      "Epoch: 38 \t Train Loss: 0.4511 \t Train CI: 0.476 \t Val CI: 0.502\n",
      "Epoch: 39 \t Train Loss: 0.4246 \t Train CI: 0.486 \t Val CI: 0.502\n",
      "Epoch: 40 \t Train Loss: 0.4374 \t Train CI: 0.480 \t Val CI: 0.503\n",
      "Epoch: 41 \t Train Loss: 0.4313 \t Train CI: 0.481 \t Val CI: 0.503\n",
      "Epoch: 42 \t Train Loss: 0.4271 \t Train CI: 0.485 \t Val CI: 0.503\n",
      "Epoch: 43 \t Train Loss: 0.4360 \t Train CI: 0.481 \t Val CI: 0.504\n",
      "Epoch: 44 \t Train Loss: 0.4322 \t Train CI: 0.478 \t Val CI: 0.504\n",
      "Epoch: 45 \t Train Loss: 0.4294 \t Train CI: 0.485 \t Val CI: 0.505\n",
      "Epoch: 46 \t Train Loss: 0.4042 \t Train CI: 0.493 \t Val CI: 0.505\n",
      "Epoch: 47 \t Train Loss: 0.4206 \t Train CI: 0.486 \t Val CI: 0.506\n",
      "Epoch: 48 \t Train Loss: 0.4155 \t Train CI: 0.486 \t Val CI: 0.506\n",
      "Epoch: 49 \t Train Loss: 0.4104 \t Train CI: 0.493 \t Val CI: 0.506\n",
      "Epoch: 50 \t Train Loss: 0.4158 \t Train CI: 0.483 \t Val CI: 0.507\n",
      "Epoch: 51 \t Train Loss: 0.4045 \t Train CI: 0.495 \t Val CI: 0.507\n",
      "Epoch: 52 \t Train Loss: 0.4062 \t Train CI: 0.490 \t Val CI: 0.508\n",
      "Epoch: 53 \t Train Loss: 0.3962 \t Train CI: 0.493 \t Val CI: 0.508\n",
      "Epoch: 54 \t Train Loss: 0.4061 \t Train CI: 0.490 \t Val CI: 0.509\n",
      "Epoch: 55 \t Train Loss: 0.3974 \t Train CI: 0.492 \t Val CI: 0.509\n",
      "Epoch: 56 \t Train Loss: 0.3976 \t Train CI: 0.494 \t Val CI: 0.509\n",
      "Epoch: 57 \t Train Loss: 0.3898 \t Train CI: 0.496 \t Val CI: 0.510\n",
      "Epoch: 58 \t Train Loss: 0.3782 \t Train CI: 0.499 \t Val CI: 0.510\n",
      "Epoch: 59 \t Train Loss: 0.3751 \t Train CI: 0.499 \t Val CI: 0.511\n",
      "Epoch: 60 \t Train Loss: 0.3881 \t Train CI: 0.495 \t Val CI: 0.511\n",
      "Epoch: 61 \t Train Loss: 0.3831 \t Train CI: 0.493 \t Val CI: 0.511\n",
      "Epoch: 62 \t Train Loss: 0.3701 \t Train CI: 0.501 \t Val CI: 0.511\n",
      "Epoch: 63 \t Train Loss: 0.3865 \t Train CI: 0.495 \t Val CI: 0.512\n",
      "Epoch: 64 \t Train Loss: 0.3726 \t Train CI: 0.499 \t Val CI: 0.512\n",
      "Epoch: 65 \t Train Loss: 0.3802 \t Train CI: 0.498 \t Val CI: 0.513\n",
      "Epoch: 66 \t Train Loss: 0.3670 \t Train CI: 0.504 \t Val CI: 0.513\n",
      "Epoch: 67 \t Train Loss: 0.3638 \t Train CI: 0.502 \t Val CI: 0.514\n",
      "Epoch: 68 \t Train Loss: 0.3702 \t Train CI: 0.501 \t Val CI: 0.514\n",
      "Epoch: 69 \t Train Loss: 0.3561 \t Train CI: 0.504 \t Val CI: 0.514\n",
      "Epoch: 70 \t Train Loss: 0.3597 \t Train CI: 0.505 \t Val CI: 0.515\n",
      "Epoch: 71 \t Train Loss: 0.3555 \t Train CI: 0.506 \t Val CI: 0.515\n",
      "Epoch: 72 \t Train Loss: 0.3580 \t Train CI: 0.503 \t Val CI: 0.516\n",
      "Epoch: 73 \t Train Loss: 0.3497 \t Train CI: 0.503 \t Val CI: 0.516\n",
      "Epoch: 74 \t Train Loss: 0.3576 \t Train CI: 0.503 \t Val CI: 0.516\n",
      "Epoch: 75 \t Train Loss: 0.3617 \t Train CI: 0.504 \t Val CI: 0.517\n",
      "Epoch: 76 \t Train Loss: 0.3456 \t Train CI: 0.511 \t Val CI: 0.517\n",
      "Epoch: 77 \t Train Loss: 0.3420 \t Train CI: 0.509 \t Val CI: 0.518\n",
      "Epoch: 78 \t Train Loss: 0.3449 \t Train CI: 0.505 \t Val CI: 0.518\n",
      "Epoch: 79 \t Train Loss: 0.3133 \t Train CI: 0.518 \t Val CI: 0.519\n",
      "Epoch: 80 \t Train Loss: 0.3487 \t Train CI: 0.508 \t Val CI: 0.519\n",
      "Epoch: 81 \t Train Loss: 0.3265 \t Train CI: 0.514 \t Val CI: 0.519\n",
      "Epoch: 82 \t Train Loss: 0.3318 \t Train CI: 0.514 \t Val CI: 0.520\n",
      "Epoch: 83 \t Train Loss: 0.3359 \t Train CI: 0.509 \t Val CI: 0.520\n",
      "Epoch: 84 \t Train Loss: 0.3097 \t Train CI: 0.519 \t Val CI: 0.521\n",
      "Epoch: 85 \t Train Loss: 0.3292 \t Train CI: 0.514 \t Val CI: 0.521\n",
      "Epoch: 86 \t Train Loss: 0.3227 \t Train CI: 0.514 \t Val CI: 0.522\n",
      "Epoch: 87 \t Train Loss: 0.3142 \t Train CI: 0.517 \t Val CI: 0.522\n",
      "Epoch: 88 \t Train Loss: 0.3169 \t Train CI: 0.517 \t Val CI: 0.523\n",
      "Epoch: 89 \t Train Loss: 0.3317 \t Train CI: 0.510 \t Val CI: 0.523\n",
      "Epoch: 90 \t Train Loss: 0.3114 \t Train CI: 0.518 \t Val CI: 0.524\n",
      "Epoch: 91 \t Train Loss: 0.3091 \t Train CI: 0.521 \t Val CI: 0.524\n",
      "Epoch: 92 \t Train Loss: 0.3125 \t Train CI: 0.523 \t Val CI: 0.525\n",
      "Epoch: 93 \t Train Loss: 0.3114 \t Train CI: 0.521 \t Val CI: 0.525\n",
      "Epoch: 94 \t Train Loss: 0.3020 \t Train CI: 0.522 \t Val CI: 0.526\n",
      "Epoch: 95 \t Train Loss: 0.3040 \t Train CI: 0.521 \t Val CI: 0.526\n",
      "Epoch: 96 \t Train Loss: 0.3206 \t Train CI: 0.516 \t Val CI: 0.527\n",
      "Epoch: 97 \t Train Loss: 0.3064 \t Train CI: 0.524 \t Val CI: 0.527\n",
      "Epoch: 98 \t Train Loss: 0.3013 \t Train CI: 0.519 \t Val CI: 0.528\n",
      "Epoch: 99 \t Train Loss: 0.2929 \t Train CI: 0.527 \t Val CI: 0.528\n",
      "Epoch: 100 \t Train Loss: 0.2951 \t Train CI: 0.522 \t Val CI: 0.529\n",
      "Epoch: 101 \t Train Loss: 0.2917 \t Train CI: 0.527 \t Val CI: 0.529\n",
      "Epoch: 102 \t Train Loss: 0.2994 \t Train CI: 0.525 \t Val CI: 0.530\n",
      "Epoch: 103 \t Train Loss: 0.2933 \t Train CI: 0.524 \t Val CI: 0.530\n",
      "Epoch: 104 \t Train Loss: 0.2832 \t Train CI: 0.527 \t Val CI: 0.531\n",
      "Epoch: 105 \t Train Loss: 0.2924 \t Train CI: 0.525 \t Val CI: 0.531\n",
      "Epoch: 106 \t Train Loss: 0.2809 \t Train CI: 0.527 \t Val CI: 0.532\n",
      "Epoch: 107 \t Train Loss: 0.2784 \t Train CI: 0.532 \t Val CI: 0.532\n",
      "Epoch: 108 \t Train Loss: 0.2726 \t Train CI: 0.530 \t Val CI: 0.533\n",
      "Epoch: 109 \t Train Loss: 0.2700 \t Train CI: 0.534 \t Val CI: 0.534\n",
      "Epoch: 110 \t Train Loss: 0.2615 \t Train CI: 0.540 \t Val CI: 0.534\n",
      "Epoch: 111 \t Train Loss: 0.2683 \t Train CI: 0.534 \t Val CI: 0.535\n",
      "Epoch: 112 \t Train Loss: 0.2571 \t Train CI: 0.538 \t Val CI: 0.535\n",
      "Epoch: 113 \t Train Loss: 0.2650 \t Train CI: 0.535 \t Val CI: 0.536\n",
      "Epoch: 114 \t Train Loss: 0.2600 \t Train CI: 0.537 \t Val CI: 0.536\n",
      "Epoch: 115 \t Train Loss: 0.2467 \t Train CI: 0.542 \t Val CI: 0.537\n",
      "Epoch: 116 \t Train Loss: 0.2515 \t Train CI: 0.541 \t Val CI: 0.537\n",
      "Epoch: 117 \t Train Loss: 0.2429 \t Train CI: 0.542 \t Val CI: 0.538\n",
      "Epoch: 118 \t Train Loss: 0.2271 \t Train CI: 0.549 \t Val CI: 0.539\n",
      "Epoch: 119 \t Train Loss: 0.2432 \t Train CI: 0.542 \t Val CI: 0.539\n",
      "Epoch: 120 \t Train Loss: 0.2463 \t Train CI: 0.542 \t Val CI: 0.540\n",
      "Epoch: 121 \t Train Loss: 0.2365 \t Train CI: 0.546 \t Val CI: 0.541\n",
      "Epoch: 122 \t Train Loss: 0.2388 \t Train CI: 0.541 \t Val CI: 0.541\n",
      "Epoch: 123 \t Train Loss: 0.2257 \t Train CI: 0.549 \t Val CI: 0.542\n",
      "Epoch: 124 \t Train Loss: 0.2322 \t Train CI: 0.544 \t Val CI: 0.542\n",
      "Epoch: 125 \t Train Loss: 0.2115 \t Train CI: 0.555 \t Val CI: 0.543\n",
      "Epoch: 126 \t Train Loss: 0.2164 \t Train CI: 0.552 \t Val CI: 0.543\n",
      "Epoch: 127 \t Train Loss: 0.2288 \t Train CI: 0.548 \t Val CI: 0.544\n",
      "Epoch: 128 \t Train Loss: 0.1941 \t Train CI: 0.557 \t Val CI: 0.545\n",
      "Epoch: 129 \t Train Loss: 0.2085 \t Train CI: 0.553 \t Val CI: 0.545\n",
      "Epoch: 130 \t Train Loss: 0.2053 \t Train CI: 0.557 \t Val CI: 0.546\n",
      "Epoch: 131 \t Train Loss: 0.2066 \t Train CI: 0.557 \t Val CI: 0.547\n",
      "Epoch: 132 \t Train Loss: 0.1988 \t Train CI: 0.561 \t Val CI: 0.548\n",
      "Epoch: 133 \t Train Loss: 0.1668 \t Train CI: 0.571 \t Val CI: 0.548\n",
      "Epoch: 134 \t Train Loss: 0.1869 \t Train CI: 0.564 \t Val CI: 0.549\n",
      "Epoch: 135 \t Train Loss: 0.1860 \t Train CI: 0.563 \t Val CI: 0.549\n",
      "Epoch: 136 \t Train Loss: 0.1810 \t Train CI: 0.567 \t Val CI: 0.550\n",
      "Epoch: 137 \t Train Loss: 0.1879 \t Train CI: 0.568 \t Val CI: 0.551\n",
      "Epoch: 138 \t Train Loss: 0.1922 \t Train CI: 0.562 \t Val CI: 0.552\n",
      "Epoch: 139 \t Train Loss: 0.1822 \t Train CI: 0.565 \t Val CI: 0.553\n",
      "Epoch: 140 \t Train Loss: 0.1607 \t Train CI: 0.572 \t Val CI: 0.553\n",
      "Epoch: 141 \t Train Loss: 0.1612 \t Train CI: 0.572 \t Val CI: 0.554\n",
      "Epoch: 142 \t Train Loss: 0.1667 \t Train CI: 0.570 \t Val CI: 0.555\n",
      "Epoch: 143 \t Train Loss: 0.1568 \t Train CI: 0.576 \t Val CI: 0.556\n",
      "Epoch: 144 \t Train Loss: 0.1486 \t Train CI: 0.579 \t Val CI: 0.557\n",
      "Epoch: 145 \t Train Loss: 0.1508 \t Train CI: 0.577 \t Val CI: 0.558\n",
      "Epoch: 146 \t Train Loss: 0.1523 \t Train CI: 0.577 \t Val CI: 0.559\n",
      "Epoch: 147 \t Train Loss: 0.1433 \t Train CI: 0.577 \t Val CI: 0.560\n",
      "Epoch: 148 \t Train Loss: 0.1430 \t Train CI: 0.584 \t Val CI: 0.561\n",
      "Epoch: 149 \t Train Loss: 0.1308 \t Train CI: 0.585 \t Val CI: 0.562\n",
      "Epoch: 150 \t Train Loss: 0.1283 \t Train CI: 0.585 \t Val CI: 0.562\n",
      "Epoch: 151 \t Train Loss: 0.1196 \t Train CI: 0.589 \t Val CI: 0.563\n",
      "Epoch: 152 \t Train Loss: 0.1159 \t Train CI: 0.588 \t Val CI: 0.565\n",
      "Epoch: 153 \t Train Loss: 0.1189 \t Train CI: 0.589 \t Val CI: 0.566\n",
      "Epoch: 154 \t Train Loss: 0.1124 \t Train CI: 0.593 \t Val CI: 0.567\n",
      "Epoch: 155 \t Train Loss: 0.1049 \t Train CI: 0.593 \t Val CI: 0.568\n",
      "Epoch: 156 \t Train Loss: 0.0982 \t Train CI: 0.595 \t Val CI: 0.569\n",
      "Epoch: 157 \t Train Loss: 0.1021 \t Train CI: 0.592 \t Val CI: 0.570\n",
      "Epoch: 158 \t Train Loss: 0.0947 \t Train CI: 0.599 \t Val CI: 0.571\n",
      "Epoch: 159 \t Train Loss: 0.0834 \t Train CI: 0.602 \t Val CI: 0.572\n",
      "Epoch: 160 \t Train Loss: 0.0863 \t Train CI: 0.602 \t Val CI: 0.573\n",
      "Epoch: 161 \t Train Loss: 0.0730 \t Train CI: 0.603 \t Val CI: 0.574\n",
      "Epoch: 162 \t Train Loss: 0.0679 \t Train CI: 0.606 \t Val CI: 0.575\n",
      "Epoch: 163 \t Train Loss: 0.0752 \t Train CI: 0.605 \t Val CI: 0.576\n",
      "Epoch: 164 \t Train Loss: 0.0564 \t Train CI: 0.610 \t Val CI: 0.577\n",
      "Epoch: 165 \t Train Loss: 0.0626 \t Train CI: 0.610 \t Val CI: 0.578\n",
      "Epoch: 166 \t Train Loss: 0.0446 \t Train CI: 0.616 \t Val CI: 0.579\n",
      "Epoch: 167 \t Train Loss: 0.0319 \t Train CI: 0.622 \t Val CI: 0.581\n",
      "Epoch: 168 \t Train Loss: 0.0298 \t Train CI: 0.620 \t Val CI: 0.582\n",
      "Epoch: 169 \t Train Loss: 0.0386 \t Train CI: 0.618 \t Val CI: 0.583\n",
      "Epoch: 170 \t Train Loss: 0.0341 \t Train CI: 0.618 \t Val CI: 0.584\n",
      "Epoch: 171 \t Train Loss: 0.0249 \t Train CI: 0.623 \t Val CI: 0.585\n",
      "Epoch: 172 \t Train Loss: 0.0231 \t Train CI: 0.625 \t Val CI: 0.586\n",
      "Epoch: 173 \t Train Loss: 0.0043 \t Train CI: 0.628 \t Val CI: 0.588\n",
      "Epoch: 174 \t Train Loss: 0.0167 \t Train CI: 0.624 \t Val CI: 0.589\n",
      "Epoch: 175 \t Train Loss: 0.0011 \t Train CI: 0.632 \t Val CI: 0.590\n",
      "Epoch: 176 \t Train Loss: -0.0103 \t Train CI: 0.633 \t Val CI: 0.591\n",
      "Epoch: 177 \t Train Loss: -0.0013 \t Train CI: 0.634 \t Val CI: 0.592\n",
      "Epoch: 178 \t Train Loss: -0.0052 \t Train CI: 0.634 \t Val CI: 0.593\n",
      "Epoch: 179 \t Train Loss: -0.0126 \t Train CI: 0.636 \t Val CI: 0.595\n",
      "Epoch: 180 \t Train Loss: -0.0354 \t Train CI: 0.642 \t Val CI: 0.596\n",
      "Epoch: 181 \t Train Loss: -0.0248 \t Train CI: 0.641 \t Val CI: 0.597\n",
      "Epoch: 182 \t Train Loss: -0.0441 \t Train CI: 0.648 \t Val CI: 0.598\n",
      "Epoch: 183 \t Train Loss: -0.0446 \t Train CI: 0.647 \t Val CI: 0.599\n",
      "Epoch: 184 \t Train Loss: -0.0496 \t Train CI: 0.650 \t Val CI: 0.600\n",
      "Epoch: 185 \t Train Loss: -0.0490 \t Train CI: 0.648 \t Val CI: 0.601\n",
      "Epoch: 186 \t Train Loss: -0.0511 \t Train CI: 0.650 \t Val CI: 0.603\n",
      "Epoch: 187 \t Train Loss: -0.0451 \t Train CI: 0.649 \t Val CI: 0.604\n",
      "Epoch: 188 \t Train Loss: -0.0733 \t Train CI: 0.656 \t Val CI: 0.606\n",
      "Epoch: 189 \t Train Loss: -0.0481 \t Train CI: 0.651 \t Val CI: 0.607\n",
      "Epoch: 190 \t Train Loss: -0.0700 \t Train CI: 0.656 \t Val CI: 0.609\n",
      "Epoch: 191 \t Train Loss: -0.0572 \t Train CI: 0.654 \t Val CI: 0.610\n",
      "Epoch: 192 \t Train Loss: -0.0828 \t Train CI: 0.662 \t Val CI: 0.612\n",
      "Epoch: 193 \t Train Loss: -0.0993 \t Train CI: 0.667 \t Val CI: 0.614\n",
      "Epoch: 194 \t Train Loss: -0.0944 \t Train CI: 0.665 \t Val CI: 0.615\n",
      "Epoch: 195 \t Train Loss: -0.1009 \t Train CI: 0.665 \t Val CI: 0.617\n",
      "Epoch: 196 \t Train Loss: -0.1071 \t Train CI: 0.670 \t Val CI: 0.618\n",
      "Epoch: 197 \t Train Loss: -0.0967 \t Train CI: 0.667 \t Val CI: 0.619\n",
      "Epoch: 198 \t Train Loss: -0.1148 \t Train CI: 0.671 \t Val CI: 0.621\n",
      "Epoch: 199 \t Train Loss: -0.1007 \t Train CI: 0.669 \t Val CI: 0.623\n",
      "Epoch: 200 \t Train Loss: -0.1054 \t Train CI: 0.671 \t Val CI: 0.624\n",
      "Epoch: 201 \t Train Loss: -0.1355 \t Train CI: 0.678 \t Val CI: 0.625\n",
      "Epoch: 202 \t Train Loss: -0.1192 \t Train CI: 0.671 \t Val CI: 0.627\n",
      "Epoch: 203 \t Train Loss: -0.1219 \t Train CI: 0.676 \t Val CI: 0.628\n",
      "Epoch: 204 \t Train Loss: -0.1331 \t Train CI: 0.676 \t Val CI: 0.629\n",
      "Epoch: 205 \t Train Loss: -0.1508 \t Train CI: 0.684 \t Val CI: 0.631\n",
      "Epoch: 206 \t Train Loss: -0.1332 \t Train CI: 0.678 \t Val CI: 0.632\n",
      "Epoch: 207 \t Train Loss: -0.1332 \t Train CI: 0.677 \t Val CI: 0.634\n",
      "Epoch: 208 \t Train Loss: -0.1384 \t Train CI: 0.680 \t Val CI: 0.635\n",
      "Epoch: 209 \t Train Loss: -0.1516 \t Train CI: 0.685 \t Val CI: 0.637\n",
      "Epoch: 210 \t Train Loss: -0.1633 \t Train CI: 0.687 \t Val CI: 0.639\n",
      "Epoch: 211 \t Train Loss: -0.1545 \t Train CI: 0.689 \t Val CI: 0.640\n",
      "Epoch: 212 \t Train Loss: -0.1494 \t Train CI: 0.685 \t Val CI: 0.642\n",
      "Epoch: 213 \t Train Loss: -0.1600 \t Train CI: 0.687 \t Val CI: 0.643\n",
      "Epoch: 214 \t Train Loss: -0.1716 \t Train CI: 0.689 \t Val CI: 0.645\n",
      "Epoch: 215 \t Train Loss: -0.1796 \t Train CI: 0.695 \t Val CI: 0.646\n",
      "Epoch: 216 \t Train Loss: -0.1683 \t Train CI: 0.692 \t Val CI: 0.648\n",
      "Epoch: 217 \t Train Loss: -0.1807 \t Train CI: 0.697 \t Val CI: 0.650\n",
      "Epoch: 218 \t Train Loss: -0.1763 \t Train CI: 0.696 \t Val CI: 0.652\n",
      "Epoch: 219 \t Train Loss: -0.1723 \t Train CI: 0.694 \t Val CI: 0.653\n",
      "Epoch: 220 \t Train Loss: -0.1709 \t Train CI: 0.694 \t Val CI: 0.655\n",
      "Epoch: 221 \t Train Loss: -0.1908 \t Train CI: 0.697 \t Val CI: 0.656\n",
      "Epoch: 222 \t Train Loss: -0.1936 \t Train CI: 0.698 \t Val CI: 0.658\n",
      "Epoch: 223 \t Train Loss: -0.1767 \t Train CI: 0.697 \t Val CI: 0.660\n",
      "Epoch: 224 \t Train Loss: -0.1943 \t Train CI: 0.703 \t Val CI: 0.661\n",
      "Epoch: 225 \t Train Loss: -0.2007 \t Train CI: 0.702 \t Val CI: 0.663\n",
      "Epoch: 226 \t Train Loss: -0.2063 \t Train CI: 0.709 \t Val CI: 0.664\n",
      "Epoch: 227 \t Train Loss: -0.1963 \t Train CI: 0.706 \t Val CI: 0.666\n",
      "Epoch: 228 \t Train Loss: -0.2016 \t Train CI: 0.704 \t Val CI: 0.667\n",
      "Epoch: 229 \t Train Loss: -0.2060 \t Train CI: 0.706 \t Val CI: 0.669\n",
      "Epoch: 230 \t Train Loss: -0.2034 \t Train CI: 0.703 \t Val CI: 0.670\n",
      "Epoch: 231 \t Train Loss: -0.1941 \t Train CI: 0.701 \t Val CI: 0.672\n",
      "Epoch: 232 \t Train Loss: -0.2160 \t Train CI: 0.709 \t Val CI: 0.673\n",
      "Epoch: 233 \t Train Loss: -0.2195 \t Train CI: 0.710 \t Val CI: 0.674\n",
      "Epoch: 234 \t Train Loss: -0.2164 \t Train CI: 0.708 \t Val CI: 0.675\n",
      "Epoch: 235 \t Train Loss: -0.2333 \t Train CI: 0.714 \t Val CI: 0.677\n",
      "Epoch: 236 \t Train Loss: -0.2137 \t Train CI: 0.708 \t Val CI: 0.678\n",
      "Epoch: 237 \t Train Loss: -0.2334 \t Train CI: 0.715 \t Val CI: 0.679\n",
      "Epoch: 238 \t Train Loss: -0.2208 \t Train CI: 0.710 \t Val CI: 0.681\n",
      "Epoch: 239 \t Train Loss: -0.2236 \t Train CI: 0.713 \t Val CI: 0.682\n",
      "Epoch: 240 \t Train Loss: -0.2286 \t Train CI: 0.716 \t Val CI: 0.683\n",
      "Epoch: 241 \t Train Loss: -0.2350 \t Train CI: 0.717 \t Val CI: 0.685\n",
      "Epoch: 242 \t Train Loss: -0.2334 \t Train CI: 0.717 \t Val CI: 0.686\n",
      "Epoch: 243 \t Train Loss: -0.2372 \t Train CI: 0.716 \t Val CI: 0.688\n",
      "Epoch: 244 \t Train Loss: -0.2343 \t Train CI: 0.716 \t Val CI: 0.690\n",
      "Epoch: 245 \t Train Loss: -0.2384 \t Train CI: 0.719 \t Val CI: 0.691\n",
      "Epoch: 246 \t Train Loss: -0.2418 \t Train CI: 0.717 \t Val CI: 0.693\n",
      "Epoch: 247 \t Train Loss: -0.2513 \t Train CI: 0.721 \t Val CI: 0.694\n",
      "Epoch: 248 \t Train Loss: -0.2292 \t Train CI: 0.716 \t Val CI: 0.695\n",
      "Epoch: 249 \t Train Loss: -0.2515 \t Train CI: 0.722 \t Val CI: 0.696\n",
      "Epoch: 250 \t Train Loss: -0.2513 \t Train CI: 0.720 \t Val CI: 0.698\n",
      "Epoch: 251 \t Train Loss: -0.2505 \t Train CI: 0.724 \t Val CI: 0.699\n",
      "Epoch: 252 \t Train Loss: -0.2641 \t Train CI: 0.723 \t Val CI: 0.700\n",
      "Epoch: 253 \t Train Loss: -0.2578 \t Train CI: 0.720 \t Val CI: 0.702\n",
      "Epoch: 254 \t Train Loss: -0.2555 \t Train CI: 0.720 \t Val CI: 0.703\n",
      "Epoch: 255 \t Train Loss: -0.2527 \t Train CI: 0.721 \t Val CI: 0.705\n",
      "Epoch: 256 \t Train Loss: -0.2604 \t Train CI: 0.723 \t Val CI: 0.706\n",
      "Epoch: 257 \t Train Loss: -0.2523 \t Train CI: 0.725 \t Val CI: 0.707\n",
      "Epoch: 258 \t Train Loss: -0.2603 \t Train CI: 0.725 \t Val CI: 0.708\n",
      "Epoch: 259 \t Train Loss: -0.2527 \t Train CI: 0.728 \t Val CI: 0.709\n",
      "Epoch: 260 \t Train Loss: -0.2562 \t Train CI: 0.725 \t Val CI: 0.710\n",
      "Epoch: 261 \t Train Loss: -0.2533 \t Train CI: 0.723 \t Val CI: 0.711\n",
      "Epoch: 262 \t Train Loss: -0.2601 \t Train CI: 0.725 \t Val CI: 0.712\n",
      "Epoch: 263 \t Train Loss: -0.2705 \t Train CI: 0.729 \t Val CI: 0.713\n",
      "Epoch: 264 \t Train Loss: -0.2658 \t Train CI: 0.728 \t Val CI: 0.714\n",
      "Epoch: 265 \t Train Loss: -0.2650 \t Train CI: 0.728 \t Val CI: 0.715\n",
      "Epoch: 266 \t Train Loss: -0.2623 \t Train CI: 0.728 \t Val CI: 0.716\n",
      "Epoch: 267 \t Train Loss: -0.2650 \t Train CI: 0.728 \t Val CI: 0.716\n",
      "Epoch: 268 \t Train Loss: -0.2588 \t Train CI: 0.725 \t Val CI: 0.717\n",
      "Epoch: 269 \t Train Loss: -0.2761 \t Train CI: 0.731 \t Val CI: 0.718\n",
      "Epoch: 270 \t Train Loss: -0.2830 \t Train CI: 0.730 \t Val CI: 0.719\n",
      "Epoch: 271 \t Train Loss: -0.2584 \t Train CI: 0.725 \t Val CI: 0.720\n",
      "Epoch: 272 \t Train Loss: -0.2637 \t Train CI: 0.730 \t Val CI: 0.721\n",
      "Epoch: 273 \t Train Loss: -0.2693 \t Train CI: 0.731 \t Val CI: 0.722\n",
      "Epoch: 274 \t Train Loss: -0.2746 \t Train CI: 0.726 \t Val CI: 0.722\n",
      "Epoch: 275 \t Train Loss: -0.2719 \t Train CI: 0.729 \t Val CI: 0.723\n",
      "Epoch: 276 \t Train Loss: -0.2741 \t Train CI: 0.728 \t Val CI: 0.724\n",
      "Epoch: 277 \t Train Loss: -0.2760 \t Train CI: 0.731 \t Val CI: 0.724\n",
      "Epoch: 278 \t Train Loss: -0.2829 \t Train CI: 0.731 \t Val CI: 0.725\n",
      "Epoch: 279 \t Train Loss: -0.2725 \t Train CI: 0.730 \t Val CI: 0.725\n",
      "Epoch: 280 \t Train Loss: -0.2799 \t Train CI: 0.730 \t Val CI: 0.726\n",
      "Epoch: 281 \t Train Loss: -0.2871 \t Train CI: 0.734 \t Val CI: 0.727\n",
      "Epoch: 282 \t Train Loss: -0.2790 \t Train CI: 0.729 \t Val CI: 0.727\n",
      "Epoch: 283 \t Train Loss: -0.2880 \t Train CI: 0.735 \t Val CI: 0.728\n",
      "Epoch: 284 \t Train Loss: -0.2630 \t Train CI: 0.725 \t Val CI: 0.729\n",
      "Epoch: 285 \t Train Loss: -0.2651 \t Train CI: 0.725 \t Val CI: 0.729\n",
      "Epoch: 286 \t Train Loss: -0.2732 \t Train CI: 0.729 \t Val CI: 0.730\n",
      "Epoch: 287 \t Train Loss: -0.2657 \t Train CI: 0.728 \t Val CI: 0.730\n",
      "Epoch: 288 \t Train Loss: -0.2870 \t Train CI: 0.731 \t Val CI: 0.731\n",
      "Epoch: 289 \t Train Loss: -0.2795 \t Train CI: 0.731 \t Val CI: 0.731\n",
      "Epoch: 290 \t Train Loss: -0.2729 \t Train CI: 0.730 \t Val CI: 0.731\n",
      "Epoch: 291 \t Train Loss: -0.2908 \t Train CI: 0.734 \t Val CI: 0.732\n",
      "Epoch: 292 \t Train Loss: -0.2834 \t Train CI: 0.733 \t Val CI: 0.732\n",
      "Epoch: 293 \t Train Loss: -0.2736 \t Train CI: 0.730 \t Val CI: 0.733\n",
      "Epoch: 294 \t Train Loss: -0.2920 \t Train CI: 0.734 \t Val CI: 0.733\n",
      "Epoch: 295 \t Train Loss: -0.2786 \t Train CI: 0.733 \t Val CI: 0.733\n",
      "Epoch: 296 \t Train Loss: -0.2844 \t Train CI: 0.736 \t Val CI: 0.733\n",
      "Epoch: 297 \t Train Loss: -0.2770 \t Train CI: 0.733 \t Val CI: 0.734\n",
      "Epoch: 298 \t Train Loss: -0.2834 \t Train CI: 0.733 \t Val CI: 0.734\n",
      "Epoch: 299 \t Train Loss: -0.2846 \t Train CI: 0.732 \t Val CI: 0.734\n",
      "Epoch: 300 \t Train Loss: -0.2830 \t Train CI: 0.733 \t Val CI: 0.734\n",
      "Epoch: 301 \t Train Loss: -0.2848 \t Train CI: 0.730 \t Val CI: 0.735\n",
      "Epoch: 302 \t Train Loss: -0.2797 \t Train CI: 0.732 \t Val CI: 0.735\n",
      "Epoch: 303 \t Train Loss: -0.2729 \t Train CI: 0.728 \t Val CI: 0.735\n",
      "Epoch: 304 \t Train Loss: -0.2832 \t Train CI: 0.731 \t Val CI: 0.735\n",
      "Epoch: 305 \t Train Loss: -0.2853 \t Train CI: 0.731 \t Val CI: 0.735\n",
      "Epoch: 306 \t Train Loss: -0.2874 \t Train CI: 0.731 \t Val CI: 0.735\n",
      "Epoch: 307 \t Train Loss: -0.2845 \t Train CI: 0.736 \t Val CI: 0.736\n",
      "Epoch: 308 \t Train Loss: -0.2914 \t Train CI: 0.733 \t Val CI: 0.736\n",
      "Epoch: 309 \t Train Loss: -0.2853 \t Train CI: 0.731 \t Val CI: 0.736\n",
      "Epoch: 310 \t Train Loss: -0.2943 \t Train CI: 0.732 \t Val CI: 0.736\n",
      "Epoch: 311 \t Train Loss: -0.2823 \t Train CI: 0.732 \t Val CI: 0.736\n",
      "Epoch: 312 \t Train Loss: -0.2908 \t Train CI: 0.736 \t Val CI: 0.736\n",
      "Epoch: 313 \t Train Loss: -0.2934 \t Train CI: 0.737 \t Val CI: 0.736\n",
      "Epoch: 314 \t Train Loss: -0.2823 \t Train CI: 0.733 \t Val CI: 0.737\n",
      "Epoch: 315 \t Train Loss: -0.2892 \t Train CI: 0.734 \t Val CI: 0.737\n",
      "Epoch: 316 \t Train Loss: -0.2722 \t Train CI: 0.729 \t Val CI: 0.737\n",
      "Epoch: 317 \t Train Loss: -0.2835 \t Train CI: 0.733 \t Val CI: 0.737\n",
      "Epoch: 318 \t Train Loss: -0.2824 \t Train CI: 0.733 \t Val CI: 0.737\n",
      "Epoch: 319 \t Train Loss: -0.2848 \t Train CI: 0.730 \t Val CI: 0.737\n",
      "Epoch: 320 \t Train Loss: -0.2915 \t Train CI: 0.736 \t Val CI: 0.737\n",
      "Epoch: 321 \t Train Loss: -0.2860 \t Train CI: 0.732 \t Val CI: 0.737\n",
      "Epoch: 322 \t Train Loss: -0.2848 \t Train CI: 0.733 \t Val CI: 0.737\n",
      "Epoch: 323 \t Train Loss: -0.2944 \t Train CI: 0.735 \t Val CI: 0.738\n",
      "Epoch: 324 \t Train Loss: -0.2897 \t Train CI: 0.732 \t Val CI: 0.738\n",
      "Epoch: 325 \t Train Loss: -0.2856 \t Train CI: 0.732 \t Val CI: 0.738\n",
      "Epoch: 326 \t Train Loss: -0.2825 \t Train CI: 0.732 \t Val CI: 0.738\n",
      "Epoch: 327 \t Train Loss: -0.2897 \t Train CI: 0.734 \t Val CI: 0.738\n",
      "Epoch: 328 \t Train Loss: -0.2970 \t Train CI: 0.735 \t Val CI: 0.738\n",
      "Epoch: 329 \t Train Loss: -0.2816 \t Train CI: 0.731 \t Val CI: 0.738\n",
      "Epoch: 330 \t Train Loss: -0.2889 \t Train CI: 0.736 \t Val CI: 0.738\n",
      "Epoch: 331 \t Train Loss: -0.2946 \t Train CI: 0.734 \t Val CI: 0.738\n",
      "Epoch: 332 \t Train Loss: -0.2866 \t Train CI: 0.736 \t Val CI: 0.738\n",
      "Epoch: 333 \t Train Loss: -0.2859 \t Train CI: 0.733 \t Val CI: 0.738\n",
      "Epoch: 334 \t Train Loss: -0.2881 \t Train CI: 0.733 \t Val CI: 0.738\n",
      "Epoch: 335 \t Train Loss: -0.2842 \t Train CI: 0.733 \t Val CI: 0.738\n",
      "Epoch: 336 \t Train Loss: -0.3002 \t Train CI: 0.738 \t Val CI: 0.738\n",
      "Epoch: 337 \t Train Loss: -0.2926 \t Train CI: 0.735 \t Val CI: 0.738\n",
      "Epoch: 338 \t Train Loss: -0.2826 \t Train CI: 0.730 \t Val CI: 0.738\n",
      "Epoch: 339 \t Train Loss: -0.2921 \t Train CI: 0.735 \t Val CI: 0.738\n",
      "Epoch: 340 \t Train Loss: -0.2974 \t Train CI: 0.737 \t Val CI: 0.738\n",
      "Epoch: 341 \t Train Loss: -0.2938 \t Train CI: 0.736 \t Val CI: 0.738\n",
      "Epoch: 342 \t Train Loss: -0.2896 \t Train CI: 0.733 \t Val CI: 0.738\n",
      "Epoch: 343 \t Train Loss: -0.2873 \t Train CI: 0.732 \t Val CI: 0.738\n",
      "Epoch: 344 \t Train Loss: -0.2837 \t Train CI: 0.733 \t Val CI: 0.738\n",
      "Epoch: 345 \t Train Loss: -0.2855 \t Train CI: 0.731 \t Val CI: 0.738\n",
      "Epoch: 346 \t Train Loss: -0.2861 \t Train CI: 0.731 \t Val CI: 0.739\n",
      "Epoch: 347 \t Train Loss: -0.2841 \t Train CI: 0.734 \t Val CI: 0.739\n",
      "Epoch: 348 \t Train Loss: -0.2857 \t Train CI: 0.732 \t Val CI: 0.739\n",
      "Epoch: 349 \t Train Loss: -0.3005 \t Train CI: 0.737 \t Val CI: 0.738\n",
      "Epoch: 350 \t Train Loss: -0.2941 \t Train CI: 0.734 \t Val CI: 0.739\n",
      "Epoch: 351 \t Train Loss: -0.2853 \t Train CI: 0.735 \t Val CI: 0.739\n",
      "Epoch: 352 \t Train Loss: -0.2912 \t Train CI: 0.735 \t Val CI: 0.739\n",
      "Epoch: 353 \t Train Loss: -0.3000 \t Train CI: 0.736 \t Val CI: 0.738\n",
      "Epoch: 354 \t Train Loss: -0.2927 \t Train CI: 0.734 \t Val CI: 0.739\n",
      "Epoch: 355 \t Train Loss: -0.2845 \t Train CI: 0.732 \t Val CI: 0.738\n",
      "Epoch: 356 \t Train Loss: -0.2916 \t Train CI: 0.733 \t Val CI: 0.739\n",
      "Epoch: 357 \t Train Loss: -0.2946 \t Train CI: 0.735 \t Val CI: 0.739\n",
      "Epoch: 358 \t Train Loss: -0.2903 \t Train CI: 0.733 \t Val CI: 0.739\n",
      "Epoch: 359 \t Train Loss: -0.3003 \t Train CI: 0.737 \t Val CI: 0.738\n",
      "Epoch: 360 \t Train Loss: -0.2864 \t Train CI: 0.733 \t Val CI: 0.738\n",
      "Epoch: 361 \t Train Loss: -0.2947 \t Train CI: 0.735 \t Val CI: 0.738\n",
      "Epoch: 362 \t Train Loss: -0.2981 \t Train CI: 0.737 \t Val CI: 0.738\n",
      "Epoch: 363 \t Train Loss: -0.3048 \t Train CI: 0.738 \t Val CI: 0.738\n",
      "Epoch: 364 \t Train Loss: -0.3029 \t Train CI: 0.736 \t Val CI: 0.738\n",
      "Epoch: 365 \t Train Loss: -0.2894 \t Train CI: 0.734 \t Val CI: 0.738\n",
      "Epoch: 366 \t Train Loss: -0.2945 \t Train CI: 0.734 \t Val CI: 0.738\n",
      "Epoch: 367 \t Train Loss: -0.2924 \t Train CI: 0.733 \t Val CI: 0.738\n",
      "Epoch: 368 \t Train Loss: -0.2945 \t Train CI: 0.735 \t Val CI: 0.738\n",
      "Epoch: 369 \t Train Loss: -0.2979 \t Train CI: 0.736 \t Val CI: 0.738\n",
      "Epoch: 370 \t Train Loss: -0.3082 \t Train CI: 0.740 \t Val CI: 0.738\n",
      "Epoch: 371 \t Train Loss: -0.2936 \t Train CI: 0.734 \t Val CI: 0.738\n",
      "Epoch: 372 \t Train Loss: -0.2993 \t Train CI: 0.735 \t Val CI: 0.738\n",
      "Epoch: 373 \t Train Loss: -0.3030 \t Train CI: 0.737 \t Val CI: 0.738\n",
      "Epoch: 374 \t Train Loss: -0.2982 \t Train CI: 0.734 \t Val CI: 0.738\n",
      "Epoch: 375 \t Train Loss: -0.2919 \t Train CI: 0.734 \t Val CI: 0.738\n",
      "Epoch: 376 \t Train Loss: -0.2930 \t Train CI: 0.732 \t Val CI: 0.738\n",
      "Epoch: 377 \t Train Loss: -0.2950 \t Train CI: 0.734 \t Val CI: 0.738\n",
      "Epoch: 378 \t Train Loss: -0.2920 \t Train CI: 0.735 \t Val CI: 0.738\n",
      "Epoch: 379 \t Train Loss: -0.3068 \t Train CI: 0.738 \t Val CI: 0.738\n",
      "Epoch: 380 \t Train Loss: -0.3100 \t Train CI: 0.736 \t Val CI: 0.738\n",
      "Epoch: 381 \t Train Loss: -0.2832 \t Train CI: 0.733 \t Val CI: 0.738\n",
      "Epoch: 382 \t Train Loss: -0.3066 \t Train CI: 0.740 \t Val CI: 0.738\n",
      "Epoch: 383 \t Train Loss: -0.2953 \t Train CI: 0.736 \t Val CI: 0.737\n",
      "Epoch: 384 \t Train Loss: -0.3057 \t Train CI: 0.739 \t Val CI: 0.737\n",
      "Epoch: 385 \t Train Loss: -0.2979 \t Train CI: 0.736 \t Val CI: 0.737\n",
      "Epoch: 386 \t Train Loss: -0.3001 \t Train CI: 0.738 \t Val CI: 0.737\n",
      "Epoch: 387 \t Train Loss: -0.3079 \t Train CI: 0.741 \t Val CI: 0.737\n",
      "Epoch: 388 \t Train Loss: -0.2957 \t Train CI: 0.734 \t Val CI: 0.737\n",
      "Epoch: 389 \t Train Loss: -0.2912 \t Train CI: 0.734 \t Val CI: 0.737\n",
      "Epoch: 390 \t Train Loss: -0.2987 \t Train CI: 0.735 \t Val CI: 0.737\n",
      "Epoch: 391 \t Train Loss: -0.2969 \t Train CI: 0.736 \t Val CI: 0.737\n",
      "Epoch: 392 \t Train Loss: -0.2904 \t Train CI: 0.733 \t Val CI: 0.737\n",
      "Epoch: 393 \t Train Loss: -0.3006 \t Train CI: 0.737 \t Val CI: 0.737\n",
      "Epoch: 394 \t Train Loss: -0.3005 \t Train CI: 0.735 \t Val CI: 0.737\n",
      "Epoch: 395 \t Train Loss: -0.3038 \t Train CI: 0.736 \t Val CI: 0.737\n",
      "Epoch: 396 \t Train Loss: -0.2947 \t Train CI: 0.736 \t Val CI: 0.737\n",
      "Epoch: 397 \t Train Loss: -0.2975 \t Train CI: 0.734 \t Val CI: 0.737\n",
      "Epoch: 398 \t Train Loss: -0.2795 \t Train CI: 0.731 \t Val CI: 0.737\n",
      "Epoch: 399 \t Train Loss: -0.3067 \t Train CI: 0.738 \t Val CI: 0.736\n",
      "Epoch: 400 \t Train Loss: -0.2921 \t Train CI: 0.733 \t Val CI: 0.736\n",
      "Epoch: 401 \t Train Loss: -0.3092 \t Train CI: 0.741 \t Val CI: 0.736\n",
      "Epoch: 402 \t Train Loss: -0.3067 \t Train CI: 0.738 \t Val CI: 0.736\n",
      "Epoch: 403 \t Train Loss: -0.3011 \t Train CI: 0.735 \t Val CI: 0.736\n",
      "Epoch: 404 \t Train Loss: -0.3017 \t Train CI: 0.738 \t Val CI: 0.736\n",
      "Epoch: 405 \t Train Loss: -0.3028 \t Train CI: 0.739 \t Val CI: 0.736\n",
      "Epoch: 406 \t Train Loss: -0.3023 \t Train CI: 0.737 \t Val CI: 0.736\n",
      "Epoch: 407 \t Train Loss: -0.3071 \t Train CI: 0.739 \t Val CI: 0.736\n",
      "Epoch: 408 \t Train Loss: -0.3116 \t Train CI: 0.741 \t Val CI: 0.736\n",
      "Epoch: 409 \t Train Loss: -0.3048 \t Train CI: 0.739 \t Val CI: 0.736\n",
      "Epoch: 410 \t Train Loss: -0.3070 \t Train CI: 0.738 \t Val CI: 0.736\n",
      "Epoch: 411 \t Train Loss: -0.3090 \t Train CI: 0.740 \t Val CI: 0.736\n",
      "Epoch: 412 \t Train Loss: -0.3115 \t Train CI: 0.740 \t Val CI: 0.735\n",
      "Epoch: 413 \t Train Loss: -0.2917 \t Train CI: 0.731 \t Val CI: 0.735\n",
      "Epoch: 414 \t Train Loss: -0.3138 \t Train CI: 0.741 \t Val CI: 0.735\n",
      "Epoch: 415 \t Train Loss: -0.3030 \t Train CI: 0.737 \t Val CI: 0.736\n",
      "Epoch: 416 \t Train Loss: -0.2996 \t Train CI: 0.737 \t Val CI: 0.735\n",
      "Epoch: 417 \t Train Loss: -0.3004 \t Train CI: 0.736 \t Val CI: 0.735\n",
      "Epoch: 418 \t Train Loss: -0.3055 \t Train CI: 0.739 \t Val CI: 0.735\n",
      "Epoch: 419 \t Train Loss: -0.3012 \t Train CI: 0.738 \t Val CI: 0.735\n",
      "Epoch: 420 \t Train Loss: -0.2999 \t Train CI: 0.737 \t Val CI: 0.735\n",
      "Epoch: 421 \t Train Loss: -0.3034 \t Train CI: 0.738 \t Val CI: 0.735\n",
      "Epoch: 422 \t Train Loss: -0.3114 \t Train CI: 0.740 \t Val CI: 0.735\n",
      "Epoch: 423 \t Train Loss: -0.3027 \t Train CI: 0.738 \t Val CI: 0.735\n",
      "Epoch: 424 \t Train Loss: -0.3164 \t Train CI: 0.741 \t Val CI: 0.735\n",
      "Epoch: 425 \t Train Loss: -0.2965 \t Train CI: 0.735 \t Val CI: 0.735\n",
      "Epoch: 426 \t Train Loss: -0.3043 \t Train CI: 0.738 \t Val CI: 0.735\n",
      "Epoch: 427 \t Train Loss: -0.3198 \t Train CI: 0.743 \t Val CI: 0.735\n",
      "Epoch: 428 \t Train Loss: -0.3106 \t Train CI: 0.740 \t Val CI: 0.735\n",
      "Epoch: 429 \t Train Loss: -0.3027 \t Train CI: 0.738 \t Val CI: 0.735\n",
      "Epoch: 430 \t Train Loss: -0.3156 \t Train CI: 0.742 \t Val CI: 0.735\n",
      "Epoch: 431 \t Train Loss: -0.3080 \t Train CI: 0.739 \t Val CI: 0.735\n",
      "Epoch: 432 \t Train Loss: -0.3063 \t Train CI: 0.742 \t Val CI: 0.735\n",
      "Epoch: 433 \t Train Loss: -0.3156 \t Train CI: 0.741 \t Val CI: 0.735\n",
      "Epoch: 434 \t Train Loss: -0.3009 \t Train CI: 0.736 \t Val CI: 0.735\n",
      "Epoch: 435 \t Train Loss: -0.3080 \t Train CI: 0.741 \t Val CI: 0.735\n",
      "Epoch: 436 \t Train Loss: -0.3090 \t Train CI: 0.739 \t Val CI: 0.735\n",
      "Epoch: 437 \t Train Loss: -0.3110 \t Train CI: 0.739 \t Val CI: 0.735\n",
      "Epoch: 438 \t Train Loss: -0.3179 \t Train CI: 0.742 \t Val CI: 0.735\n",
      "Epoch: 439 \t Train Loss: -0.3160 \t Train CI: 0.742 \t Val CI: 0.735\n",
      "Epoch: 440 \t Train Loss: -0.3086 \t Train CI: 0.739 \t Val CI: 0.735\n",
      "Epoch: 441 \t Train Loss: -0.3076 \t Train CI: 0.740 \t Val CI: 0.735\n",
      "Epoch: 442 \t Train Loss: -0.3009 \t Train CI: 0.737 \t Val CI: 0.735\n",
      "Epoch: 443 \t Train Loss: -0.3095 \t Train CI: 0.739 \t Val CI: 0.735\n",
      "Epoch: 444 \t Train Loss: -0.3070 \t Train CI: 0.740 \t Val CI: 0.735\n",
      "Epoch: 445 \t Train Loss: -0.3144 \t Train CI: 0.743 \t Val CI: 0.735\n",
      "Epoch: 446 \t Train Loss: -0.3075 \t Train CI: 0.741 \t Val CI: 0.735\n",
      "Epoch: 447 \t Train Loss: -0.3191 \t Train CI: 0.745 \t Val CI: 0.735\n",
      "Epoch: 448 \t Train Loss: -0.3207 \t Train CI: 0.743 \t Val CI: 0.735\n",
      "Epoch: 449 \t Train Loss: -0.3184 \t Train CI: 0.742 \t Val CI: 0.735\n",
      "Epoch: 450 \t Train Loss: -0.3150 \t Train CI: 0.743 \t Val CI: 0.735\n",
      "Epoch: 451 \t Train Loss: -0.3128 \t Train CI: 0.742 \t Val CI: 0.735\n",
      "Epoch: 452 \t Train Loss: -0.3194 \t Train CI: 0.743 \t Val CI: 0.735\n",
      "Epoch: 453 \t Train Loss: -0.3165 \t Train CI: 0.744 \t Val CI: 0.735\n",
      "Epoch: 454 \t Train Loss: -0.3194 \t Train CI: 0.744 \t Val CI: 0.735\n",
      "Epoch: 455 \t Train Loss: -0.3125 \t Train CI: 0.741 \t Val CI: 0.735\n",
      "Epoch: 456 \t Train Loss: -0.3182 \t Train CI: 0.743 \t Val CI: 0.735\n",
      "Epoch: 457 \t Train Loss: -0.3205 \t Train CI: 0.745 \t Val CI: 0.735\n",
      "Epoch: 458 \t Train Loss: -0.3171 \t Train CI: 0.743 \t Val CI: 0.735\n",
      "Epoch: 459 \t Train Loss: -0.3190 \t Train CI: 0.743 \t Val CI: 0.735\n",
      "Epoch: 460 \t Train Loss: -0.3294 \t Train CI: 0.745 \t Val CI: 0.735\n",
      "Epoch: 461 \t Train Loss: -0.3320 \t Train CI: 0.748 \t Val CI: 0.735\n",
      "Epoch: 462 \t Train Loss: -0.3235 \t Train CI: 0.745 \t Val CI: 0.735\n",
      "Epoch: 463 \t Train Loss: -0.3178 \t Train CI: 0.742 \t Val CI: 0.735\n",
      "Epoch: 464 \t Train Loss: -0.3239 \t Train CI: 0.745 \t Val CI: 0.735\n",
      "Epoch: 465 \t Train Loss: -0.3280 \t Train CI: 0.747 \t Val CI: 0.735\n",
      "Epoch: 466 \t Train Loss: -0.3252 \t Train CI: 0.746 \t Val CI: 0.735\n",
      "Epoch: 467 \t Train Loss: -0.3128 \t Train CI: 0.742 \t Val CI: 0.735\n",
      "Epoch: 468 \t Train Loss: -0.3169 \t Train CI: 0.742 \t Val CI: 0.735\n",
      "Epoch: 469 \t Train Loss: -0.3185 \t Train CI: 0.744 \t Val CI: 0.735\n",
      "Epoch: 470 \t Train Loss: -0.3265 \t Train CI: 0.746 \t Val CI: 0.735\n",
      "Epoch: 471 \t Train Loss: -0.3175 \t Train CI: 0.744 \t Val CI: 0.735\n",
      "Epoch: 472 \t Train Loss: -0.3226 \t Train CI: 0.744 \t Val CI: 0.735\n",
      "Epoch: 473 \t Train Loss: -0.3252 \t Train CI: 0.746 \t Val CI: 0.735\n",
      "Epoch: 474 \t Train Loss: -0.3217 \t Train CI: 0.744 \t Val CI: 0.735\n",
      "Epoch: 475 \t Train Loss: -0.3305 \t Train CI: 0.747 \t Val CI: 0.735\n",
      "Epoch: 476 \t Train Loss: -0.3221 \t Train CI: 0.746 \t Val CI: 0.735\n",
      "Epoch: 477 \t Train Loss: -0.3319 \t Train CI: 0.746 \t Val CI: 0.735\n",
      "Epoch: 478 \t Train Loss: -0.3201 \t Train CI: 0.744 \t Val CI: 0.735\n",
      "Epoch: 479 \t Train Loss: -0.3228 \t Train CI: 0.745 \t Val CI: 0.735\n",
      "Epoch: 480 \t Train Loss: -0.3318 \t Train CI: 0.748 \t Val CI: 0.735\n",
      "Epoch: 481 \t Train Loss: -0.3278 \t Train CI: 0.748 \t Val CI: 0.735\n",
      "Epoch: 482 \t Train Loss: -0.3246 \t Train CI: 0.744 \t Val CI: 0.735\n",
      "Epoch: 483 \t Train Loss: -0.3290 \t Train CI: 0.747 \t Val CI: 0.735\n",
      "Epoch: 484 \t Train Loss: -0.3301 \t Train CI: 0.746 \t Val CI: 0.736\n",
      "Epoch: 485 \t Train Loss: -0.3262 \t Train CI: 0.746 \t Val CI: 0.736\n",
      "Epoch: 486 \t Train Loss: -0.3275 \t Train CI: 0.747 \t Val CI: 0.736\n",
      "Epoch: 487 \t Train Loss: -0.3245 \t Train CI: 0.745 \t Val CI: 0.736\n",
      "Epoch: 488 \t Train Loss: -0.3350 \t Train CI: 0.749 \t Val CI: 0.736\n",
      "Epoch: 489 \t Train Loss: -0.3302 \t Train CI: 0.748 \t Val CI: 0.736\n",
      "Epoch: 490 \t Train Loss: -0.3277 \t Train CI: 0.745 \t Val CI: 0.736\n",
      "Epoch: 491 \t Train Loss: -0.3273 \t Train CI: 0.746 \t Val CI: 0.736\n",
      "Epoch: 492 \t Train Loss: -0.3331 \t Train CI: 0.750 \t Val CI: 0.736\n",
      "Epoch: 493 \t Train Loss: -0.3173 \t Train CI: 0.745 \t Val CI: 0.736\n",
      "Epoch: 494 \t Train Loss: -0.3241 \t Train CI: 0.748 \t Val CI: 0.736\n",
      "Epoch: 495 \t Train Loss: -0.3330 \t Train CI: 0.748 \t Val CI: 0.736\n",
      "Epoch: 496 \t Train Loss: -0.3224 \t Train CI: 0.745 \t Val CI: 0.736\n",
      "Epoch: 497 \t Train Loss: -0.3311 \t Train CI: 0.749 \t Val CI: 0.736\n",
      "Epoch: 498 \t Train Loss: -0.3204 \t Train CI: 0.745 \t Val CI: 0.736\n",
      "Epoch: 499 \t Train Loss: -0.3243 \t Train CI: 0.744 \t Val CI: 0.736\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, args.epochs):\n",
    "    coxLossMeter = AverageMeter()\n",
    "    stratLossMeter = AverageMeter()\n",
    "    ciMeter = AverageMeter()\n",
    "    varMeter = AverageMeter()\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    for X, y, e in train_loader:\n",
    "        # Get risk prediction from network\n",
    "        risk_pred = model(X.float().to(gpu))\n",
    "        \n",
    "        # Calculate neg. log likelihood\n",
    "        cox_loss = criterion(-risk_pred, y.to(gpu), e.to(gpu), model)\n",
    "        strat_loss = torch.Tensor([0])\n",
    "        train_loss = cox_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        coxLossMeter.update(cox_loss.item(), y.size(0))\n",
    "        stratLossMeter.update(strat_loss.item(), y.size(0))\n",
    "        varMeter.update(risk_pred.var(), y.size(0))\n",
    "        \n",
    "        # Calculate c index\n",
    "        train_c = c_index(risk_pred, y, e)\n",
    "        ciMeter.update(train_c.item(), y.size(0))\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    ciValMeter = AverageMeter()\n",
    "    for X, y, e in val_loader:\n",
    "        risk_pred = model(X.float().to(gpu))\n",
    "        val_c = c_index(risk_pred, y, e)\n",
    "        ciValMeter.update(val_c.item(), y.size(0))\n",
    "    \n",
    "    print('Epoch: {} \\t Train Loss: {:.4f} \\t Train CI: {:.3f} \\t Val CI: {:.3f}'.format(epoch, train_loss, train_c, val_c))\n",
    "    save_error(ciMeter.avg, ciValMeter.avg, coxLossMeter.avg, stratLossMeter.avg, varMeter.avg, epoch, os.path.join(out_dir, 'convergence.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepicc",
   "language": "python",
   "name": "deepicc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
