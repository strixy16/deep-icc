{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from lifelines.utils import concordance_index\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "# from pysurvival.models.simulations import SimulationModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# from utils import *\n",
    "# from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models.py\n",
    "Code from Hassan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "    ''' The module class performs building network according to config'''\n",
    "    def __init__(self, activation, covariates):\n",
    "        ''' Initialize BasicModel class\n",
    "\n",
    "        Args:\n",
    "            activation: string, name of activation function to use\n",
    "            covariates: int, number of covariates, needed for size of first layer\n",
    "\n",
    "        Returns:\n",
    "            torch.nn Module object, built sequential network\n",
    "        '''\n",
    "        super(BasicModel, self).__init__()\n",
    "        # parses parameters of network from configuration\n",
    "        # Set some defaults for network arguments\n",
    "        # Fraction of input units to drop in dropout layer\n",
    "        self.drop = 0.375#0.401\n",
    "        # Flag to in/exclude normalization layers\n",
    "        self.norm = True\n",
    "        # Default dimensions of fully connected layers\n",
    "        self.dims = [covariates, 4, 1]#10, 17, 17, 17, 1]\n",
    "        # Activation type to use\n",
    "        self.activation = activation\n",
    "        # Build network using class function (below)\n",
    "        self.model = self._build_network()\n",
    "\n",
    "    def _build_network(self):\n",
    "        ''' Performs building networks according to parameters'''\n",
    "        layers = []\n",
    "        for i in range(len(self.dims)-1):\n",
    "            if i and self.drop is not None:\n",
    "                # Add dropout layer\n",
    "                layers.append(nn.Dropout(self.drop))\n",
    "\n",
    "            # Add fully connected layer\n",
    "            layers.append(nn.Linear(self.dims[i], self.dims[i+1]))\n",
    "\n",
    "            if self.norm:\n",
    "                # Add batchnormalize layer\n",
    "                layers.append(nn.BatchNorm1d(self.dims[i+1]))\n",
    "\n",
    "            # Adds activation layer\n",
    "            # eval creates proper format of activation to get from NN\n",
    "            layers.append(eval('nn.{}()'.format(self.activation)))\n",
    "\n",
    "        # Build sequential network from list of layers created in for loop\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        ''' Forward propagation through network\n",
    "\n",
    "        Args:\n",
    "            X: data to pass through network\n",
    "\n",
    "        Returns:\n",
    "            Output of model (risk prediction)\n",
    "        '''\n",
    "        return self.model(X)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class NegativeLogLikelihood(nn.Module):\n",
    "    '''Negative log likelihood loss function from Katzman et al. (2018) DeepSurv model (equation 4)'''\n",
    "    def __init__(self, gpu):\n",
    "        ''' Initialize NegativeLogLikelihood class\n",
    "\n",
    "        Args:\n",
    "            gpu: string, what kind of tensor to use for loss calculation\n",
    "        '''\n",
    "        super(NegativeLogLikelihood, self).__init__()\n",
    "        # self.L2_reg = 0\n",
    "        self.reg = Regularization(order=2, weight_decay=0)\n",
    "        self.device = gpu\n",
    "\n",
    "    def forward(self, risk_pred, y, e, model):\n",
    "        # Think this is getting set of patients still at risk of failure at time t???\n",
    "        mask = torch.ones(y.shape[0], y.shape[0], device=self.device)\n",
    "        mask[(y.T - y) > 0] = 0\n",
    "        log_loss = torch.exp(risk_pred) * mask\n",
    "        log_loss = torch.sum(log_loss, dim=0) / torch.sum(mask, dim=0)\n",
    "        log_loss = torch.log(log_loss).reshape(-1, 1)\n",
    "        neg_log_loss = -torch.sum((risk_pred-log_loss) * e) / torch.sum(e)\n",
    "        l2_loss = self.reg(model)\n",
    "        return neg_log_loss + l2_loss\n",
    "\n",
    "\n",
    "class NegativeLogLikelihoodStrat(nn.Module):\n",
    "    def __init__(self, gpu):\n",
    "        super(NegativeLogLikelihoodStrat, self).__init__()\n",
    "        self.device = gpu\n",
    "\n",
    "    def forward(self, risk_pred, y, e, low, high):\n",
    "        mask = torch.ones(y.shape[0], y.shape[0], device=self.device)\n",
    "        mask[(y.T - y) > 0] = 0\n",
    "        log_loss = torch.exp(risk_pred) * mask\n",
    "        log_loss = torch.sum(log_loss, dim=0) / torch.sum(mask, dim=0)\n",
    "        log_loss = torch.log(log_loss).reshape(-1, 1)\n",
    "        neg_log_loss = -torch.sum((risk_pred-log_loss) * e) / torch.sum(e)\n",
    "        strat_loss = 1 / (1 + torch.abs((high.mean() - low.mean())))\n",
    "        strat_loss = F.smooth_l1_loss(strat_loss, torch.zeros(1).squeeze().to(self.device), reduction='none').to(self.device)\n",
    "        return neg_log_loss, strat_loss\n",
    "\n",
    "\n",
    "class Regularization(object):\n",
    "    def __init__(self, order, weight_decay):\n",
    "        ''' Initialize Regularization class\n",
    "\n",
    "        Args:\n",
    "            order: int, norm order number\n",
    "            weight_decay: float, weight decay rate\n",
    "        '''\n",
    "        super(Regularization, self).__init__()\n",
    "        self.order = order\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def __call__(self, model):\n",
    "        ''' Calculates regularization(self.order) loss for model\n",
    "\n",
    "        Args:\n",
    "            model: torch.nn Module object\n",
    "\n",
    "        Returns:\n",
    "            reg_loss: torch.Tensor, regularization loss\n",
    "        '''\n",
    "        reg_loss = 0\n",
    "        for name, w in model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                reg_loss = reg_loss + torch.norm(w, p=self.order)\n",
    "        reg_loss = self.weight_decay * reg_loss\n",
    "        return reg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils.py\n",
    "Code from Hassan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurvivalDataset(Dataset):\n",
    "    def __init__(self, dataset, args):\n",
    "        '''Initialize SurvivalDataset class\n",
    "\n",
    "        Args:\n",
    "            dataset: pandas.Dataframe, Contains covariates, time of event (T), and event indicator (E) values.\n",
    "            T and E must be the final two columns\n",
    "            args: Namespace,\n",
    "        '''\n",
    "        # Get covariates out of dataframe (args.covariates is num of columns containing covariates)\n",
    "        self.X = dataset.iloc[:, 0:args.covariates].values\n",
    "        # Get time and event indicator columns out of dataframe\n",
    "        self.data = list(zip(dataset.time, dataset.event))\n",
    "        self.len = len(dataset)\n",
    "        print('=> load {} samples'.format(self.len))\n",
    "        # Normalize covariate data with class function\n",
    "        if args.normalize:\n",
    "            self._normalize()\n",
    "\n",
    "    def _normalize(self):\n",
    "        '''Normalize X data (covariates) (transform values to range between 0 and 1)'''\n",
    "        self.X = (self.X - self.X.min(axis=0)) / (self.X.max(axis=0) - self.X.min(axis=0))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        '''Getter for single data piece\n",
    "\n",
    "        Args:\n",
    "            item: int, index of data to retrieve\n",
    "\n",
    "        Returns:\n",
    "            X_tensor: torch.Tensor, covariate values for data item\n",
    "            y_tensor: torch.Tensor, time of event value for data item\n",
    "            e_tensor: int torch.Tensor, event indicator value for data item\n",
    "        '''\n",
    "        y, e = self.data[item]\n",
    "        X_tensor = torch.from_numpy(self.X[item])\n",
    "        e_tensor = torch.Tensor([e]).int()\n",
    "        y_tensor = torch.Tensor([y])\n",
    "        return X_tensor, y_tensor, e_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "\n",
    "def save_error(train_ci, val_ci, coxLoss, stratLoss, variance, epoch, slname):\n",
    "    '''Save training and validation statistics to csv file\n",
    "\n",
    "        Args:\n",
    "            train_ci: float, training concordance index for this epoch\n",
    "            val_ci: float, validation concordance index for this epoch\n",
    "            coxLoss:\n",
    "            stratLoss:\n",
    "            variance:\n",
    "            epoch: int, epoch these stats are from\n",
    "            slname: string, filename\n",
    "    '''\n",
    "    if epoch == 0:\n",
    "        # Create file for first epoch\n",
    "        f = open(slname, 'w')\n",
    "        f.write('epoch,coxLoss,stratLoss,trainCI,valCI,variance\\n')\n",
    "        f.write('{},{:.4f},{:.4f},{:.4f},{:.4f},{}\\n'.format(epoch, coxLoss, stratLoss, train_ci, val_ci, variance))\n",
    "        f.close()\n",
    "    else:\n",
    "        f = open(slname, 'a')\n",
    "        f.write('{},{:.4f},{:.4f},{:.4f},{:.4f},{}\\n'.format(epoch, coxLoss, stratLoss, train_ci, val_ci, variance))\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def c_index(risk_pred, y, e):\n",
    "    '''Calculate c-index\n",
    "\n",
    "    Args:\n",
    "        risk_pred: np.ndarray or torch.Tensor, model prediction\n",
    "        y: np.ndarray or torch.Tensor, times of event e\n",
    "        e: np.ndarray or torch.Tensor, event indicator\n",
    "\n",
    "    Returns:\n",
    "        c_index: float, concordance index\n",
    "    '''\n",
    "    # Convert risk_pred, y, and e from torch.Tensor to np.ndarray if not already\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = y.detach().cpu().numpy()\n",
    "    if not isinstance(risk_pred, np.ndarray):\n",
    "        risk_pred = risk_pred.detach().cpu().numpy()\n",
    "    if not isinstance(e, np.ndarray):\n",
    "        e = e.detach().cpu().numpy()\n",
    "    return concordance_index(y, risk_pred, e)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, lr, lr_decay_rate):\n",
    "    '''Adjust learning rate according to (epoch, lr, and lr_decay_rate)\n",
    "\n",
    "    Args:\n",
    "        optimizer: torch.optim object,\n",
    "        epoch: int, epoch number\n",
    "        lr: float, initial learning rate\n",
    "        lr_decay_rate: float, decay rate to apply to learning rate\n",
    "\n",
    "    Returns:\n",
    "        lr: float, updated learning rate\n",
    "    '''\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr / (1+epoch*lr_decay_rate)\n",
    "    return optimizer.param_groups[0]['lr']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.py\n",
    "Code from Hassan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for network\n",
    "args = Namespace(activation = 'SELU',  # activation for fully connected layers\n",
    "                 batch_size = 4000,    # this is currently ignored by the DataLoader\n",
    "                 covariates = 18,      # input size, will be size of first layer\n",
    "                 decay_interval = 400, # how many epochs pass before weight decay is applied\n",
    "                 development = True,   # if testing, sends output to separate directory\n",
    "                 dropout = 0.3,        # Dropout rate \n",
    "                 epochs = 500,         # Training epoch count\n",
    "                 lr = 0.001,           # Learning rate\n",
    "                 normalize = False,    # Whether to normalize covariate data \n",
    "                 weight_decay = 0.0001 # Decay rate for weights\n",
    "                )\n",
    "\n",
    "best_acc = 0\n",
    "# Where to allocate all the Tensors (can be 'cpu' or 'coda')\n",
    "gpu = torch.device(\"cpu\")\n",
    "\n",
    "# Setting up output path from model training\n",
    "# Mac directory \n",
    "# root_output = '/Users/katyscott/Documents/ICC/Code/cox_experiments'\n",
    "\n",
    "# Linux directory\n",
    "root_output = '/media/katy/Data/ICC/Code/cox_experiments'\n",
    "\n",
    "if args.development:\n",
    "    save_path = 'test'\n",
    "else:\n",
    "    save_path = '{}_{}lr_{}b_'.format(args.activation,args.lr,args.batch_size)\n",
    "    \n",
    "out_dir = os.path.join(root_output, save_path)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulated Data creation\n",
    "\n",
    "*Note: this is currently broken on Linux, can't install pysurvival. Works on Mac.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random survival times with exp. distribution\n",
    "# sim = SimulationModel(survival_distribution='exponential',\n",
    "#                       risk_type = 'Linear',\n",
    "#                       censored_parameter = 6,\n",
    "#                       alpha = 1,\n",
    "#                       beta = 5)\n",
    "\n",
    "# train_samples = sim.generate_data(num_samples = 4000,\n",
    "#                                   num_features = args.covariates,\n",
    "#                                   feature_weights = [1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "# val_samples = sim.generate_data(num_samples = 500,\n",
    "#                                 num_features = args.covariates,\n",
    "#                                 feature_weights = [1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "# train_dataset = SurvivalDataset(train_samples, args)\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_dataset.__len__())\n",
    "\n",
    "# val_dataset = SurvivalDataset(val_samples, args)\n",
    "# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=val_dataset.__len__())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and setup cholangio genetic data\n",
    "genomic_file = \"../Data/MSK_Genomic_Data.csv\"\n",
    "\n",
    "gene_features = pd.read_csv(genomic_file)\n",
    "#Patient IDs have a space at the end of the name\n",
    "gene_features['ScoutID'] = gene_features['ScoutID'].str.strip()\n",
    "# Fixing columns with illegal characters in name\n",
    "gene_features.rename(columns={'CDKN2A.DEL':'CDKN2A_DEL', 'TGF-Beta_Pathway':'TGF_Beta_Pathway'}, inplace=True)\n",
    "\n",
    "# Get number of covariates = number of genetic columns\n",
    "args.covariates = gene_features.shape[1] - 1\n",
    "\n",
    "labels_file = \"../Data/RFS_Scout.xlsx\"\n",
    "\n",
    "rfs_labels = pd.read_excel(labels_file)\n",
    "rfs_labels = rfs_labels[['ScoutID', 'RFS', 'RFS_Code']]\n",
    "rfs_labels.rename(columns={'RFS':'time', 'RFS_Code':'event'}, inplace=True)\n",
    "\n",
    "# Getting intersection of patients with gene features and RFS labels all in one dataframe\n",
    "genes_and_labels = pd.merge(gene_features, rfs_labels, how='inner', on=['ScoutID', 'ScoutID'])\n",
    "\n",
    "# Removing ScoutID so setup is proper for Survival Dataset generation\n",
    "genes_and_labels.drop(columns=['ScoutID'], inplace=True)\n",
    "\n",
    "train_genes, val_genes = train_test_split(genes_and_labels, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> load 88 samples\n",
      "=> load 23 samples\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SurvivalDataset(train_genes, args)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_dataset.__len__())\n",
    "\n",
    "val_dataset = SurvivalDataset(val_genes, args)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=val_dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build network \n",
    "model = BasicModel(args.activation, args.covariates).to(gpu)\n",
    "\n",
    "# Loss function\n",
    "criterion = NegativeLogLikelihood(gpu)\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, args.epochs):\n",
    "    coxLossMeter = AverageMeter()\n",
    "    stratLossMeter = AverageMeter()\n",
    "    ciMeter = AverageMeter()\n",
    "    varMeter = AverageMeter()\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    for X, y, e in train_loader:\n",
    "        # Get risk prediction from network\n",
    "        risk_pred = model(X.float().to(gpu))\n",
    "        \n",
    "        # Calculate neg. log likelihood\n",
    "        cox_loss = criterion(-risk_pred, y.to(gpu), e.to(gpu), model)\n",
    "        strat_loss = torch.Tensor([0])\n",
    "        train_loss = cox_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        coxLossMeter.update(cox_loss.item(), y.size(0))\n",
    "        stratLossMeter.update(strat_loss.item(), y.size(0))\n",
    "        varMeter.update(risk_pred.var(), y.size(0))\n",
    "        \n",
    "        # Calculate c index\n",
    "        train_c = c_index(risk_pred, y, e)\n",
    "        ciMeter.update(train_c.item(), y.size(0))\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    ciValMeter = AverageMeter()\n",
    "    for X, y, e in val_loader:\n",
    "        risk_pred = model(X.float().to(gpu))\n",
    "        val_c = c_index(risk_pred, y, e)\n",
    "        ciValMeter.update(val_c.item(), y.size(0))\n",
    "    \n",
    "    print('Epoch: {} \\t Train Loss: {:.4f} \\t Train CI: {:.3f} \\t Val CI: {:.3f}'.format(epoch, train_loss, train_c, val_c))\n",
    "    save_error(ciMeter.avg, ciValMeter.avg, coxLossMeter.avg, stratLossMeter.avg, varMeter.avg, epoch, os.path.join(out_dir, 'convergence.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
