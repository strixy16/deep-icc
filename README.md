

# Survival Time Prediction with Radiographic Images for Primary and Metastatic Liver Cancers

*Katy Scott* 

This repository is the official implementation of (My M.Sc. Thesis/Published paper?)


## File Descriptions :open_file_folder:
* ***image_preprocessing/*** :arrow_right: contains MatLab code for preprocessing .raw and .mhd files to .bin files for use in main. Configuration files must be generated like all_HDFS_liver.m, HDFS_train_liver.m, and HDFS_test_liver.m to be used in main_preprocessing and main_train_test_script.
  * ***main_preprocessing.m*** :arrow_right: Set config as the main configuration file you want to use, should be set up like all_HDFS_liver.m for example. Crops and saves the corresponding images as bin files and creates label spreadsheet for deep learning code.
  * ***new_preprocessMHA.m*** :arrow_right: Function that converts .raw and .mhd to .bin files. Called in main_preprocessing.
  * ***createCSV_HDFS.m*** :arrow_right: Function that creates a CSV file connecting patients to file names, slices, and HDFS labels. Called in main_preprocessing and main_train_test_script.
  * ***erasmus_tumors/msk_tumor*** :arrow_right: configuration files for preprocessMHA
  
  * ***main_train_test_script.m*** :arrow_right: Splits data into train and test sets. Main config is same as main_preprocessing. 
  * ***train_test_split_HDFS*** :arrow_right: Copies bin files generated by main_preprocessing into train and test folders. Called in main_train_test_script.
Remaining functions are helper functions used in the preprocessing pipeline.

* ***main.ipynb*** :arrow_right: Main notebook for deep-icc. Contains all model functions, data loading, and three of the models that were trained in the development process. Training results presented in report can be visualized in this notebook.

* ***patient_data_split.py*** :arrow_right: Function to properly split patient data into train and test sets. Split is performed so CT slices from a single patient are not spread across sets.

* ***data_explore.ipynb*** :arrow_right: Notebook containing exploratory code. Includes data distribution plots, Kaplan Meier survival curve, linear regression, and attempt at Cox Proportional Hazards modelling

* ***ckpts-kt6-cnn-100*** :arrow_right: Saved Tensorflow checkpoints for KT6 model

* ***WorkLog.txt*** :arrow_right: Log of work completed so far. Was the original README so is formatted in that way.

* ***old_code/***: :arrow_right: Code written in process of development. Was either broken and abandoned or absorbed into the files listed above.


## Requirements üìã
To run image preprocessing, MATLAB R2020b or later is required.

To setup the model in a conda environment, run the following:

```setup
conda create --name deepicc -f environment.yml
jupyter lab
```
Make sure the kernel is set to Python3 and you can now run the main and data_explore notebooks.

## Image Preprocessing üñºÔ∏è

To use the MATLAB preprocessing functions, preprocessMHA and createCSV, you will need:
* A directory of corresponding MHD and raw files
* A spreadsheet with labels for each sample

First create a configuration file for your dataset. You can follow the setup of msk_tumor and all_tumors. The variables required are:

*For preprocessMHA*
* ImageSize: dimensions to crop your image to for the network (ex. \[256 x 256]) 
* ImageLoc: path to the directory your MHD and raw files are in
* BinLoc: path to the directory to store the output BIN files

*For createCSV*
* ZeroLoc: path to directory of BIN files with zeros for background
* Labels: path to spreadsheet file containing labels 
* CSV_header: Set headings for label output CSV
* OutputCSV: path and name of output CSV linking labels to BIN files

To crop images based on max height and width for that set, run this command in MATLAB:
``` 
preprocessMHA(config_file);
createCSV(config_file); 
```
This should generate a directory of individual BIN files for each slice of the MHD volume and a corresponding CSV label file.

## Model Training üèÉ

Model creation and training is available in `main.ipynb`

The data used to train the KT6 model described in the report is not publicly available. 
Output from training this model is included in the notebook. `ckpts-kt-100` contains the stored training checkpoints that can be loaded into the Tensorboard at the end of the notebook.


## Results üìà

My model achieves the following performance:

|     Model name     |    C-index   |
| ------------------ | ------------ | 
|       KT6          |     0.54     |




